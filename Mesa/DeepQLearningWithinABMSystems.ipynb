{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from mesa import Model\n",
    "from mesa.time import RandomActivation\n",
    "from sklearn import ensemble\n",
    "from mesa.space import MultiGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "from scipy.stats import truncnorm\n",
    "from t_agent import TerroristAgent\n",
    "from c_agent import CivilianAgent\n",
    "from m_agent import MilitaryAgent\n",
    "from dqn_tf import DeepQNetwork\n",
    "from hivemind_ter import HiveMindTer\n",
    "from hivemind_mil import HiveMindMil\n",
    "from gen_agents import GenAgents\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "class MapModel(Model):\n",
    "\n",
    "    def __init__(self, density=.1, height=50, width=50, map_size=\"Large\", troop_size=10000,\n",
    "                t_hive=HiveMindTer(gamma=0.99, epsilon=1.0, alpha=0.00025, input_dims=(1, 15, 1),\n",
    "                                n_actions=5, mem_size=4000, batch_size=1),\n",
    "                m_hive=HiveMindMil(gamma=0.99, epsilon=1.0, alpha=0.00025, input_dims=(1, 7, 1),\n",
    "                                n_actions=4, mem_size=4000, batch_size=1)):\n",
    "\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.density = density\n",
    "        self.map_size = map_size\n",
    "        self.gen_agents = GenAgents()\n",
    "        self.load_checkpoints = True\n",
    "\n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.grid = MultiGrid(height, width, False)\n",
    "\n",
    "        self.terror_score = 0\n",
    "        self.civilian_score = 0\n",
    "\n",
    "        self.pred_agents = self.gen_agents.generate_pred_agents(10000)\n",
    "        self.pred_model = self.train_model(self.pred_agents)\n",
    "        self.t_hive = t_hive\n",
    "        self.m_hive = m_hive\n",
    "\n",
    "        self.datacollector = DataCollector({\"Terrorist Epsilon\": \"t_epsilon\", \"Military Epsilon\": \"m_epsilon\"})\n",
    "\n",
    "        if self.load_checkpoints:\n",
    "            self.t_hive.load_models()\n",
    "            self.m_hive.load_models()\n",
    "\n",
    "        self.t_epsilon = self.t_hive.epsilon\n",
    "        self.m_epsilon = self.m_hive.epsilon\n",
    "\n",
    "        self.metro_size = 10000\n",
    "        self.metro_civ = int(self.metro_size * (1 - self.density))\n",
    "        self.metro_ter = int(self.metro_size * self.density)\n",
    "\n",
    "        self.city_size = 1000\n",
    "        self.city_civ = int(self.city_size * (1 - self.density))\n",
    "        self.city_ter = int(self.city_size * self.density)\n",
    "\n",
    "        self.village = 50\n",
    "        self.village_civ = int(self.village * (1 - self.density))\n",
    "        self.village_ter = int(self.village * self.density)\n",
    "\n",
    "        self.troop_size = troop_size\n",
    "\n",
    "        if self.map_size == \"Large\":\n",
    "            self.basecamp = int(self.troop_size * .8)\n",
    "            self.outpost = int(self.troop_size * .2)\n",
    "            self.metro_loc = {\"X\": 25, \"Y\": 25}\n",
    "            self.city1_loc = {\"X\": 20, \"Y\": 20}\n",
    "            self.city2_loc = {\"X\": 45, \"Y\": 25}\n",
    "            self.village1_loc = {\"X\": 10, \"Y\": 45}\n",
    "            self.village2_loc = {\"X\": 15, \"Y\": 30}\n",
    "            self.village3_loc = {\"X\": 45, \"Y\": 45}\n",
    "            self.basecamp_loc = {\"X\": 35, \"Y\": 10}\n",
    "            self.outpost_loc = {\"X\": 30, \"Y\": 20}\n",
    "            self.metro_t_agents = self.gen_agents.generate_ter_agents(self.metro_ter)\n",
    "            self.metro_c_agents = self.gen_agents.generate_civ_agents(self.metro_civ)\n",
    "            self.city1_t_agents = self.gen_agents.generate_ter_agents(self.city_ter)\n",
    "            self.city1_c_agents = self.gen_agents.generate_civ_agents(self.city_civ)\n",
    "            self.city2_t_agents = self.gen_agents.generate_ter_agents(self.city_ter)\n",
    "            self.city2_c_agents = self.gen_agents.generate_civ_agents(self.city_civ)\n",
    "            self.village1_t_agents = self.gen_agents.generate_ter_agents(self.village_ter)\n",
    "            self.village1_c_agents = self.gen_agents.generate_civ_agents(self.village_civ)\n",
    "            self.village2_t_agents = self.gen_agents.generate_ter_agents(self.village_ter)\n",
    "            self.village2_c_agents = self.gen_agents.generate_civ_agents(self.village_civ)\n",
    "            self.village3_t_agents = self.gen_agents.generate_ter_agents(self.village_ter)\n",
    "            self.village3_c_agents = self.gen_agents.generate_civ_agents(self.village_civ)\n",
    "            self.basecamp_agents = self.gen_agents.generate_mil_agents(self.basecamp)\n",
    "            self.outpost_agents = self.gen_agents.generate_mil_agents(self.outpost)\n",
    "            for x in range(len(self.metro_t_agents)):\n",
    "                a = TerroristAgent('tm'+str(x), self, self.metro_t_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.metro_loc[\"X\"], self.metro_loc[\"Y\"]))\n",
    "            for x in range(len(self.metro_c_agents)):\n",
    "                a = CivilianAgent('cm'+str(x), self, self.metro_c_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.metro_loc[\"X\"], self.metro_loc[\"Y\"]))\n",
    "            for x in range(len(self.city1_t_agents)):\n",
    "                a = TerroristAgent('tc1'+str(x), self, self.city1_t_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.city1_loc[\"X\"], self.city1_loc[\"Y\"]))\n",
    "            for x in range(len(self.city1_c_agents)):\n",
    "                a = CivilianAgent('cc1'+str(x), self, self.city1_c_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.city1_loc[\"X\"], self.city1_loc[\"Y\"]))\n",
    "            for x in range(len(self.city2_t_agents)):\n",
    "                a = TerroristAgent('tc2'+str(x), self, self.city2_t_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.city2_loc[\"X\"], self.city2_loc[\"Y\"]))\n",
    "            for x in range(len(self.city2_c_agents)):\n",
    "                a = CivilianAgent('cc2'+str(x), self, self.city2_c_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.city2_loc[\"X\"], self.city2_loc[\"Y\"]))\n",
    "            for x in range(len(self.village1_t_agents)):\n",
    "                a = TerroristAgent('tv1'+str(x), self, self.village1_t_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.village1_loc[\"X\"], self.village1_loc[\"Y\"]))\n",
    "            for x in range(len(self.village1_c_agents)):\n",
    "                a = CivilianAgent('cv1'+str(x), self, self.village1_c_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.village1_loc[\"X\"], self.village1_loc[\"Y\"]))\n",
    "            for x in range(len(self.village2_t_agents)):\n",
    "                a = TerroristAgent('tv2'+str(x), self, self.village2_t_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.village2_loc[\"X\"], self.village2_loc[\"Y\"]))\n",
    "            for x in range(len(self.village2_c_agents)):\n",
    "                a = CivilianAgent('cv2'+str(x), self, self.village2_c_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.village2_loc[\"X\"], self.village2_loc[\"Y\"]))\n",
    "            for x in range(len(self.village3_t_agents)):\n",
    "                a = TerroristAgent('tv3'+str(x), self, self.village3_t_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.village3_loc[\"X\"], self.village3_loc[\"Y\"]))\n",
    "            for x in range(len(self.village3_c_agents)):\n",
    "                a = CivilianAgent('cv3'+str(x), self, self.village3_c_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.village3_loc[\"X\"], self.village3_loc[\"Y\"]))\n",
    "            for x in range(len(self.basecamp_agents)):\n",
    "                a = MilitaryAgent('mb'+str(x), self, self.basecamp_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.basecamp_loc[\"X\"], self.basecamp_loc[\"Y\"]))\n",
    "            for x in range(len(self.outpost_agents)):\n",
    "                a = MilitaryAgent('mo'+str(x), self, self.outpost_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.outpost_loc[\"X\"], self.outpost_loc[\"Y\"]))\n",
    "            del self.metro_c_agents\n",
    "            del self.metro_t_agents\n",
    "            del self.city1_c_agents\n",
    "            del self.city1_t_agents\n",
    "            del self.city2_c_agents\n",
    "            del self.city2_t_agents\n",
    "            del self.village1_c_agents\n",
    "            del self.village1_t_agents\n",
    "            del self.village2_c_agents\n",
    "            del self.village2_t_agents\n",
    "            del self.village3_c_agents\n",
    "            del self.village3_t_agents\n",
    "            del self.basecamp\n",
    "            del self.outpost\n",
    "            del self.basecamp_agents\n",
    "            del self.outpost_agents\n",
    "\n",
    "        elif self.map_size == \"Medium\":\n",
    "            self.basecamp = self.troop_size\n",
    "            self.metro_loc = {\"X\": 25, \"Y\": 25}\n",
    "            self.city1_loc = {\"X\": 20, \"Y\": 20}\n",
    "            self.city2_loc = {\"X\": 45, \"Y\": 25}\n",
    "            self.basecamp_loc = {\"X\": 30, \"Y\": 20}\n",
    "            self.metro_t_agents = self.gen_agents.generate_ter_agents(self.metro_ter)\n",
    "            self.metro_c_agents = self.gen_agents.generate_civ_agents(self.metro_civ)\n",
    "            self.city1_t_agents = self.gen_agents.generate_ter_agents(self.city_ter)\n",
    "            self.city1_c_agents = self.gen_agents.generate_civ_agents(self.city_civ)\n",
    "            self.city2_t_agents = self.gen_agents.generate_ter_agents(self.city_ter)\n",
    "            self.city2_c_agents = self.gen_agents.generate_civ_agents(self.city_civ)\n",
    "            self.basecamp_agents = self.gen_agents.generate_mil_agents(self.troop_size)\n",
    "            for x in range(len(self.metro_t_agents)):\n",
    "                a = TerroristAgent('tm'+str(x), self, self.metro_t_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.metro_loc[\"X\"], self.metro_loc[\"Y\"]))\n",
    "            for x in range(len(self.metro_c_agents)):\n",
    "                a = CivilianAgent('cm'+str(x), self, self.metro_c_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.metro_loc[\"X\"], self.metro_loc[\"Y\"]))\n",
    "            for x in range(len(self.city1_t_agents)):\n",
    "                a = TerroristAgent('tc1'+str(x), self, self.city1_t_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.city1_loc[\"X\"], self.city1_loc[\"Y\"]))\n",
    "            for x in range(len(self.city1_c_agents)):\n",
    "                a = CivilianAgent('cc1'+str(x), self, self.city1_c_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.city1_loc[\"X\"], self.city1_loc[\"Y\"]))\n",
    "            for x in range(len(self.city2_t_agents)):\n",
    "                a = TerroristAgent('tc2'+str(x), self, self.city2_t_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.city2_loc[\"X\"], self.city2_loc[\"Y\"]))\n",
    "            for x in range(len(self.city2_c_agents)):\n",
    "                a = CivilianAgent('cc2'+str(x), self, self.city2_c_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.city2_loc[\"X\"], self.city2_loc[\"Y\"]))\n",
    "            for x in range(len(self.basecamp_agents)):\n",
    "                a = MilitaryAgent('mb'+str(x), self, self.basecamp_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.basecamp_loc[\"X\"], self.basecamp_loc[\"Y\"]))\n",
    "\n",
    "            del self.metro_c_agents\n",
    "            del self.metro_t_agents\n",
    "            del self.city1_c_agents\n",
    "            del self.city1_t_agents\n",
    "            del self.city2_c_agents\n",
    "            del self.city2_t_agents\n",
    "            del self.basecamp\n",
    "            del self.basecamp_agents\n",
    "\n",
    "        elif self.map_size == \"Small\":\n",
    "            self.basecamp = self.troop_size\n",
    "            self.metro_loc = {\"X\": 25, \"Y\": 25}\n",
    "            self.basecamp_loc = {\"X\": 30, \"Y\": 20}\n",
    "            self.metro_t_agents = self.gen_agents.generate_ter_agents(self.metro_ter)\n",
    "            self.metro_c_agents = self.gen_agents.generate_civ_agents(self.metro_civ)\n",
    "            self.basecamp_agents = self.gen_agents.generate_mil_agents(self.troop_size)\n",
    "            for x in range(len(self.metro_t_agents)):\n",
    "                a = TerroristAgent('tm'+str(x), self, self.metro_t_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.metro_loc[\"X\"], self.metro_loc[\"Y\"]))\n",
    "            for x in range(len(self.metro_c_agents)):\n",
    "                a = CivilianAgent('cm'+str(x), self, self.metro_c_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.metro_loc[\"X\"], self.metro_loc[\"Y\"]))\n",
    "            for x in range(len(self.basecamp_agents)):\n",
    "                a = MilitaryAgent('mb'+str(x), self, self.basecamp_agents[x:x+1])\n",
    "                self.schedule.add(a)\n",
    "                self.grid.place_agent(a, (self.basecamp_loc[\"X\"], self.basecamp_loc[\"Y\"]))\n",
    "\n",
    "            del self.metro_c_agents\n",
    "            del self.metro_t_agents\n",
    "            del self.basecamp\n",
    "            del self.basecamp_agents\n",
    "\n",
    "        del self.pred_agents\n",
    "        del self.metro_size\n",
    "        del self.metro_civ\n",
    "        del self.metro_ter\n",
    "        del self.city_civ\n",
    "        del self.city_ter\n",
    "        del self.village_civ\n",
    "        del self.village_ter\n",
    "\n",
    "        self.set_terror_score()\n",
    "        self.set_civil_score()\n",
    "\n",
    "        self.running = True\n",
    "\n",
    "    def step(self):\n",
    "        if self.get_agent_count('Terrorist') >= 1:\n",
    "            self.schedule.step()\n",
    "            self.t_epsilon = self.t_hive.epsilon\n",
    "            self.m_epsilon = self.m_hive.epsilon\n",
    "            self.datacollector.collect(self)\n",
    "            if self.schedule.steps % 5 == 0:\n",
    "                self.t_hive.save_models()\n",
    "                self.m_hive.save_models()\n",
    "        else:\n",
    "            self.running = False\n",
    "\n",
    "    def get_agent_count(self, type):\n",
    "        count = 0\n",
    "        for agent in self.schedule.agents:\n",
    "            if agent.type == type:\n",
    "                count += 1\n",
    "\n",
    "        return count\n",
    "\n",
    "    def get_agent_list(self, type):\n",
    "        agents = []\n",
    "        for agent in self.schedule.agents:\n",
    "            if agent.type == type:\n",
    "                agents.append(agent)\n",
    "\n",
    "        return agents\n",
    "\n",
    "    def set_terror_score(self):\n",
    "        t_count = self.get_agent_count('Terrorist')\n",
    "        c_count = self.get_agent_count('Civilian')\n",
    "        m_count = self.get_agent_count('Military')\n",
    "\n",
    "        if t_count >= c_count:\n",
    "            self.terror_score = t_count - (c_count/2) - m_count\n",
    "        else:\n",
    "            self.terror_score = t_count - c_count - m_count\n",
    "\n",
    "    def set_civil_score(self):\n",
    "        t_count = self.get_agent_count('Terrorist')\n",
    "        c_count = self.get_agent_count('Civilian')\n",
    "        m_count = self.get_agent_count('Military')\n",
    "\n",
    "        self.civilian_score = c_count + (m_count / 2) - t_count\n",
    "\n",
    "    def get_same_square_agents(self, x_pos, y_pos):\n",
    "        agents = []\n",
    "        for agent in self.schedule.agents:\n",
    "            if agent.pos[0] == x_pos and agent.pos[1] == y_pos:\n",
    "                agents.append(agent)\n",
    "\n",
    "        return agents\n",
    "\n",
    "    def get_same_square_type_agents(self, x_pos, y_pos, type):\n",
    "        agents = []\n",
    "        for agent in self.schedule.agents:\n",
    "            if agent.pos[0] == x_pos and agent.pos[1] == y_pos and agent.type == type:\n",
    "                agents.append(agent)\n",
    "\n",
    "        return agents\n",
    "\n",
    "    def get_neighbor_type(self, agent, type):\n",
    "        agents = self.grid.neighbor_iter((agent.pos[0], agent.pos[1]), moore=True)\n",
    "        refined = []\n",
    "        for agent in agents:\n",
    "            if agent.type == type:\n",
    "                refined.append(agent)\n",
    "                \n",
    "        return refined\n",
    "\n",
    "    def find_nearest_agent(self, agent1, agents):\n",
    "        dists = []\n",
    "        x_pos = agent1.pos[0]\n",
    "        y_pos = agent1.pos[1]\n",
    "        for agent in agents:\n",
    "            x = agent.pos[0]\n",
    "            x2 = (x - x_pos) ** 2\n",
    "            y = agent.pos[1]\n",
    "            y2 = (y - y_pos) ** 2\n",
    "            dist = np.sqrt(x2 + y2)\n",
    "            dists.append(dist)\n",
    "\n",
    "        min_index = dists.index(min(dists))\n",
    "\n",
    "        return agents[min_index]\n",
    "\n",
    "    def move_toward_nearest(self, agent1, agent2):\n",
    "        x = (agent1.pos[0] - agent2.pos[0]) // -2\n",
    "        y = (agent1.pos[1] - agent2.pos[1]) // -2\n",
    "\n",
    "\n",
    "        if x > 0:\n",
    "            x = 1\n",
    "        elif x == 0:\n",
    "            x = 0\n",
    "        elif x < 0:\n",
    "            x = -1\n",
    "\n",
    "        if y > 0:\n",
    "            y = 1\n",
    "        elif y == 0:\n",
    "            y = 0\n",
    "        elif y < 0:\n",
    "            y = -1\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def add_terrorist(self, agent, x_pos, y_pos):\n",
    "        a = TerroristAgent('t'+agent.unique_id, self, agent)\n",
    "        self.schedule.add(a)\n",
    "        self.grid.place_agent(a, (x_pos, y_pos))\n",
    "\n",
    "\n",
    "    def train_model(self, agents):\n",
    "        rfg = ensemble.RandomForestRegressor()\n",
    "        X = agents.drop(['prob_threat'], 1)\n",
    "        Y = agents.prob_threat\n",
    "\n",
    "        rfg.fit(X, Y)\n",
    "\n",
    "        return rfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa import Agent\n",
    "import numpy as np\n",
    "\n",
    "class TerroristAgent(Agent):\n",
    "\n",
    "    def __init__(self, unique_id, model, agent):\n",
    "        super().__init__(unique_id, model)\n",
    "        \n",
    "        self.wounded = False\n",
    "        self.wounded_count = 0\n",
    "        self.age = int(agent.age)\n",
    "        self.gender = int(agent.gender)\n",
    "        self.religion = int(agent.religion)\n",
    "        self.char_list = ['agr_bhv', 'rel_fnt', 'rel_conv', 'hst_twd_for', 'lvl_rct_act', 'crt_agr_lvl']\n",
    "        self.agr_bhv = float(agent.agr_bhv)\n",
    "        self.rel_fnt = float(agent.rel_fnt)\n",
    "        self.rel_conv = float(agent.rel_conv)\n",
    "        self.hst_twd_for = float(agent.hst_twd_for)\n",
    "        self.lvl_rct_act = float(agent.lvl_rct_act)\n",
    "        self.crt_agr_lvl = float(agent.crt_agr_lvl)\n",
    "        self.prob_threat = 0\n",
    "        self.type = 'Terrorist'\n",
    "        self.state = [self.gender, self.religion, self.agr_bhv, self.rel_fnt, self.rel_conv,\n",
    "                        self.hst_twd_for, self.lvl_rct_act, self.crt_agr_lvl, self.model.terror_score,\n",
    "                        self.model.civilian_score, 0, 0, self.model.get_agent_count('Terrorist'), \n",
    "                        self.model.get_agent_count('Civilian'), self.model.get_agent_count('Military')]\n",
    "\n",
    "    def step(self):\n",
    "        self.grow()\n",
    "        if not self.wounded:\n",
    "            self.choose_action(self.model.t_hive.choose_action(np.expand_dims(np.array(self.state).reshape((1, 15, 1)), 1)))\n",
    "        else:\n",
    "            if self.wounded_count > 0:\n",
    "                self.wounded_count -= 1\n",
    "            else:\n",
    "                self.wounded = False\n",
    "        self.model.t_hive.learn()\n",
    "        self.model.t_gamma = self.model.t_hive.gamma\n",
    "            \n",
    "    def grow(self):\n",
    "        if((self.agr_bhv >= .75) or (self.rel_fnt >= .75) or (self.hst_twd_for >= .75) or (self.crt_agr_lvl >= .65)):\n",
    "            self.crt_agr_lvl += .005\n",
    "        if((self.agr_bhv <= .25) or (self.rel_fnt <= .25) or (self.hst_twd_for <= .25) or (self.crt_agr_lvl <= .25)):\n",
    "            self.crt_agr_lvl -= .005\n",
    "        if((self.agr_bhv >= .75) and ((self.rel_fnt > .75) or (self.hst_twd_for) >= .75)):\n",
    "            self.crt_agr_lvl += .05\n",
    "        if((self.agr_bhv <= .25) and ((self.rel_fnt < .25) or (self.hst_twd_for) <= .25)):\n",
    "            self.crt_agr_lvl +- .05\n",
    "\n",
    "        self.agr_bhv += 0.00001\n",
    "        self.rel_fnt += 0.00001\n",
    "        self.rel_conv += 0.00001\n",
    "        self.hst_twd_for += 0.00001\n",
    "        self.crt_agr_lvl += 0.00001\n",
    "        \n",
    "        if np.random.random() <= 0.05:\n",
    "            choice = np.random.choice(self.char_list)\n",
    "            attr_value = getattr(self, choice)\n",
    "            setattr(self, choice, attr_value * np.random.random())\n",
    "\n",
    "        self.prob_threat = float(self.model.pred_model.predict([[self.age, self.gender, self.religion, self.agr_bhv, self.rel_fnt,\n",
    "                                                self.rel_conv, self.hst_twd_for, self.lvl_rct_act, self.crt_agr_lvl]]))\n",
    "    \n",
    "    def choose_action(self, action):\n",
    "        if action == 0:\n",
    "            state = np.array(self.state).reshape((1, 15 ,1))\n",
    "            t_score = self.model.terror_score\n",
    "            agents = self.model.get_same_square_agents(self.pos[0], self.pos[1])\n",
    "            deaths = np.array([1,2])#,3,4,5,6,7,8,9,10,25])\n",
    "            choice = np.random.choice(deaths)\n",
    "            if len(agents) > choice:\n",
    "                killed_agents = np.random.choice(agents, choice, replace=False)\n",
    "                for agent in killed_agents:\n",
    "                        self.model.schedule.remove(agent)\n",
    "                self.model.schedule.remove(self)\n",
    "            self.model.set_terror_score()\n",
    "            self.model.set_civil_score()\n",
    "            t_score_ = self.model.terror_score\n",
    "            state_ = np.array([self.gender, self.religion, 0, 0, 0, 0, 0, 0, self.model.terror_score, self.model.civilian_score,\n",
    "                        self.pos[0], self.pos[1], self.model.get_agent_count('Terrorist'),\n",
    "                        self.model.get_agent_count('Civilian'), self.model.get_agent_count('Military')])\n",
    "            self.state = state_\n",
    "            state_ = state_.reshape((1,15,1))\n",
    "            if t_score >= t_score_:\n",
    "                reward = -1\n",
    "            else:\n",
    "                reward = 1\n",
    "            self.model.t_hive.store_transition(state, action, reward, state_)\n",
    "            '''\n",
    "            Remove this agent from the schedule\n",
    "            Remove a random number of agents on this square from the schedule\n",
    "            '''\n",
    "        elif action == 1:\n",
    "            state = np.array(self.state).reshape((1, 15, 1))\n",
    "            t_score = self.model.terror_score\n",
    "            agents = self.model.get_same_square_type_agents(self.pos[0], self.pos[1], 'Civilian')\n",
    "            if len(agents) > 0:\n",
    "                selected_agent = np.random.choice(agents)\n",
    "                if selected_agent.rel_conv <= self.rel_conv:\n",
    "                    self.model.add_terrorist(selected_agent, self.pos[0], self.pos[1])\n",
    "                    self.model.schedule.remove(selected_agent)\n",
    "            self.model.set_terror_score()\n",
    "            self.model.set_civil_score()\n",
    "            t_score_ = self.model.terror_score\n",
    "            state_ = np.array([self.gender, self.religion, self.agr_bhv, self.rel_fnt, self.rel_conv,\n",
    "                        self.hst_twd_for, self.lvl_rct_act, self.crt_agr_lvl, self.model.terror_score,\n",
    "                        self.model.civilian_score, self.pos[0], self.pos[1], self.model.get_agent_count('Terrorist'), \n",
    "                        self.model.get_agent_count('Civilian'), self.model.get_agent_count('Military')])\n",
    "            self.state = state_\n",
    "            state_ = state_.reshape((1, 15, 1))\n",
    "            if t_score >= t_score_:\n",
    "                reward = -1\n",
    "            else:\n",
    "                reward = 1\n",
    "            self.model.t_hive.store_transition(state, action, reward, state_)\n",
    "            '''\n",
    "            Find a random civilian agent on the same square.\n",
    "            If civilian agent rel_conv < agent rel_conv, civilian agent becomes a terrorist agent\n",
    "            '''\n",
    "        elif action == 2:\n",
    "            reward = 0\n",
    "            state = np.array(self.state).reshape((1, 15, 1))\n",
    "            t_score = self.model.terror_score\n",
    "            mil_neighbors = self.model.get_neighbor_type(self, 'Military')\n",
    "            civ_neighbors = self.model.get_neighbor_type(self, 'Civilian')\n",
    "            if len(mil_neighbors) > 0:\n",
    "                choice = np.random.choice(mil_neighbors)\n",
    "                rand = np.random.random()\n",
    "                if rand >= 0.7:\n",
    "                    choice.wounded = True\n",
    "                    choice.wounded_count = 3\n",
    "                elif rand <= 0.2 and rand > 0.05:\n",
    "                    self.model.schedule.remove(choice)\n",
    "                    reward += 1\n",
    "                elif rand <= 0.05:\n",
    "                    if len(civ_neighbors) > 0:\n",
    "                        choice2 = np.random.choice(civ_neighbors)\n",
    "                        self.model.schedule.remove(choice2)\n",
    "            self.model.set_terror_score()\n",
    "            self.model.set_civil_score()\n",
    "            t_score_ = self.model.terror_score\n",
    "            state_ = np.array([self.gender, self.religion, self.agr_bhv, self.rel_fnt, self.rel_conv,\n",
    "                        self.hst_twd_for, self.lvl_rct_act, self.crt_agr_lvl, self.model.terror_score,\n",
    "                        self.model.civilian_score, self.pos[0], self.pos[1], self.model.get_agent_count('Terrorist'), \n",
    "                        self.model.get_agent_count('Civilian'), self.model.get_agent_count('Military')])\n",
    "            self.state = state_\n",
    "            state_ = state_.reshape((1, 15, 1))\n",
    "            if t_score >= t_score_:\n",
    "                reward += -1\n",
    "            else:\n",
    "                reward += 1\n",
    "            self.model.t_hive.store_transition(state, action, reward, state_)\n",
    "            '''\n",
    "            Find a military agent within 1 square of agent.\n",
    "            30% chance to wound, 20% to kill. \n",
    "            5% chance to kill civilian\n",
    "            '''\n",
    "        elif action == 3:\n",
    "            state = np.array(self.state).reshape((1, 15, 1))\n",
    "            t_score = self.model.terror_score\n",
    "            agents = self.model.get_agent_list('Military')\n",
    "            if len(agents) > 0:\n",
    "                nearest = self.model.find_nearest_agent(self, agents)\n",
    "                x, y = self.model.move_toward_nearest(self, nearest)\n",
    "                self.model.grid.move_agent(self, (self.pos[0]+x, self.pos[1]+y))\n",
    "            self.model.set_terror_score()\n",
    "            self.model.set_civil_score()\n",
    "            t_score_ = self.model.terror_score\n",
    "            state_ = np.array([self.gender, self.religion, self.agr_bhv, self.rel_fnt, self.rel_conv,\n",
    "                        self.hst_twd_for, self.lvl_rct_act, self.crt_agr_lvl, self.model.terror_score,\n",
    "                        self.model.civilian_score, self.pos[0], self.pos[1], self.model.get_agent_count('Terrorist'), \n",
    "                        self.model.get_agent_count('Civilian'), self.model.get_agent_count('Military')])\n",
    "            self.state = state_\n",
    "            state_ = state_.reshape((1, 15, 1))\n",
    "            if t_score >= t_score_:\n",
    "                reward = -1\n",
    "            else:\n",
    "                reward = 1\n",
    "            self.model.t_hive.store_transition(state, action, reward, state_)\n",
    "            '''\n",
    "            Find the nearest military agent and move toward.\n",
    "            '''\n",
    "        elif action == 4:\n",
    "            state = np.array(self.state).reshape((1, 15, 1))\n",
    "            t_score = self.model.terror_score\n",
    "            self.model.set_terror_score()\n",
    "            self.model.set_civil_score()\n",
    "            t_score_ = self.model.terror_score\n",
    "            state_ = np.array([self.gender, self.religion, self.agr_bhv, self.rel_fnt, self.rel_conv,\n",
    "                        self.hst_twd_for, self.lvl_rct_act, self.crt_agr_lvl, self.model.terror_score,\n",
    "                        self.model.civilian_score, self.pos[0], self.pos[1], self.model.get_agent_count('Terrorist'), \n",
    "                        self.model.get_agent_count('Civilian'), self.model.get_agent_count('Military')])\n",
    "            self.state = state_\n",
    "            state_ = state_.reshape((1, 15, 1))\n",
    "            if t_score >= t_score_:\n",
    "                reward = -1\n",
    "            else:\n",
    "                reward = 1\n",
    "            self.model.t_hive.store_transition(state, action, reward, state_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa import Agent\n",
    "import numpy as np\n",
    "\n",
    "class MilitaryAgent(Agent):\n",
    "    \n",
    "    def __init__(self, unique_id, model, agent):\n",
    "        super().__init__(unique_id, model)\n",
    "        \n",
    "        self.wounded = False\n",
    "        self.wounded_count = 0\n",
    "        self.state = [self.model.terror_score, self.model.civilian_score, 0, 0,\n",
    "                    self.model.get_agent_count('Terrorist'), self.model.get_agent_count('Civilian'),\n",
    "                    self.model.get_agent_count('Military')]\n",
    "        self.type = \"Military\"\n",
    "        \n",
    "    def step(self):\n",
    "        if not self.wounded:\n",
    "            self.choose_action(self.model.m_hive.choose_action(np.expand_dims(np.array(self.state).reshape((1, 7, 1)), 1)))\n",
    "        else:\n",
    "            if self.wounded_count > 0:\n",
    "                self.wounded_count -= 1\n",
    "            else:\n",
    "                self.wounded = False\n",
    "        self.model.m_hive.learn()\n",
    "        self.model.m_gamma = self.model.m_hive.gamma\n",
    "        \n",
    "    def choose_action(self, action):\n",
    "        self.action = action\n",
    "        if self.action == 0:\n",
    "            state = np.array(self.state).reshape((1, 7, 1))\n",
    "            c_score = self.model.civilian_score\n",
    "            agents = self.model.get_agent_list('Terrorist')\n",
    "            if len(agents) > 0:\n",
    "                nearest = self.model.find_nearest_agent(self, agents)\n",
    "                x, y = self.model.move_toward_nearest(self, nearest)\n",
    "                self.model.grid.move_agent(self, (self.pos[0]+x, self.pos[1]+y))\n",
    "            self.model.set_terror_score()\n",
    "            self.model.set_civil_score()\n",
    "            c_score_ = self.model.civilian_score\n",
    "            state_ = np.array([self.model.terror_score,    self.model.civilian_score, self.pos[0], self.pos[1],\n",
    "                        self.model.get_agent_count('Terrorist'), self.model.get_agent_count('Civilian'),\n",
    "                        self.model.get_agent_count('Military')])\n",
    "            self.state = state_\n",
    "            state_ = state_.reshape((1, 7, 1))\n",
    "            if c_score >= c_score_:\n",
    "                reward = -1\n",
    "            else:\n",
    "                reward = 1\n",
    "            self.model.m_hive.store_transition(state, action, reward, state_)\n",
    "            '''\n",
    "            Agent find nearest terrorist agent and moves toward.\n",
    "            '''\n",
    "        elif self.action == 1:\n",
    "            state = np.array(self.state).reshape((1, 7, 1))\n",
    "            c_score = self.model.civilian_score\n",
    "            reward = 0\n",
    "            agents = self.model.get_same_square_type_agents(self.pos[0], self.pos[1], 'Terrorist')\n",
    "            if len(agents) > 0:\n",
    "                selected_agent = np.random.choice(agents)\n",
    "                rand = np.random.random()\n",
    "                if rand <= 0.4:\n",
    "                    self.model.schedule.remove(selected_agent)\n",
    "                    reward += 2\n",
    "            self.model.set_terror_score()\n",
    "            self.model.set_civil_score()\n",
    "            c_score_ = self.model.civilian_score\n",
    "            state_ = np.array([self.model.terror_score,    self.model.civilian_score, self.pos[0], self.pos[1],\n",
    "                        self.model.get_agent_count('Terrorist'), self.model.get_agent_count('Civilian'),\n",
    "                        self.model.get_agent_count('Military')])\n",
    "            self.state = state_\n",
    "            state_ = state_.reshape((1, 7, 1))\n",
    "            if c_score >= c_score_:\n",
    "                reward = -1\n",
    "            else:\n",
    "                reward = 1\n",
    "            self.model.m_hive.store_transition(state, action, reward, state_)\n",
    "            '''\n",
    "            Agent randomly chooses a terrorist agent within the same square\n",
    "            40% success rate, reward is 2-3x larger\n",
    "            '''\n",
    "        elif self.action == 2:\n",
    "            reward = 0\n",
    "            state = np.array(self.state).reshape((1, 7, 1))\n",
    "            c_score = self.model.civilian_score\n",
    "            ter_neighbors = self.model.get_neighbor_type(self, 'Terrorist')\n",
    "            civ_neighbors = self.model.get_neighbor_type(self, 'Civilian')\n",
    "            if len(ter_neighbors) > 0:\n",
    "                choice = np.random.choice(ter_neighbors)\n",
    "                rand = np.random.random()\n",
    "                if rand >= 0.6:\n",
    "                    choice.wounded = True\n",
    "                    choice.wounded_count = 3\n",
    "                elif rand <= 0.4 and rand > 0.05:\n",
    "                    self.model.schedule.remove(choice)\n",
    "                elif rand <= 0.05:\n",
    "                    if len(civ_neighbors) > 0:\n",
    "                        choice2 = np.random.choice(civ_neighbors)\n",
    "                        self.model.schedule.remove(choice2)\n",
    "                        reward -= 1\n",
    "            self.model.set_terror_score()\n",
    "            self.model.set_civil_score()\n",
    "            c_score_ = self.model.civilian_score\n",
    "            state_ = np.array([self.model.terror_score,    self.model.civilian_score, self.pos[0], self.pos[1],\n",
    "                        self.model.get_agent_count('Terrorist'), self.model.get_agent_count('Civilian'),\n",
    "                        self.model.get_agent_count('Military')])\n",
    "            self.state = state_\n",
    "            state_ = state_.reshape((1, 7, 1))\n",
    "            if c_score >= c_score_:\n",
    "                reward += -1\n",
    "            else:\n",
    "                reward += 1\n",
    "            self.model.m_hive.store_transition(state, action, reward, state_)\n",
    "            '''\n",
    "            Agent randomly selects a terrorist agent within 1 square and attacks.\n",
    "            60% to wound, 40% to kill.\n",
    "            5% to kill civilian agent\n",
    "            '''\n",
    "        elif self.action == 3:\n",
    "            state = np.array(self.state).reshape((1, 7, 1))\n",
    "            c_score = self.model.civilian_score\n",
    "            self.model.set_terror_score()\n",
    "            self.model.set_civil_score()\n",
    "            c_score_ = self.model.civilian_score\n",
    "            state_ = np.array([self.model.terror_score,    self.model.civilian_score, self.pos[0], self.pos[1],\n",
    "                        self.model.get_agent_count('Terrorist'), self.model.get_agent_count('Civilian'),\n",
    "                        self.model.get_agent_count('Military')])\n",
    "            self.state = state_\n",
    "            state_ = state_.reshape((1, 7, 1))\n",
    "            if c_score >= c_score_:\n",
    "                reward = -1\n",
    "            else:\n",
    "                reward = 1\n",
    "            self.model.m_hive.store_transition(state, action, reward, state_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa import Agent\n",
    "\n",
    "class CivilianAgent(Agent):\n",
    "\n",
    "    def __init__(self, unique_id, model, agent):\n",
    "        super().__init__(unique_id, model)\n",
    "\n",
    "        self.age = int(agent.ages)\n",
    "        self.gender = int(agent.gender)\n",
    "        self.religion = int(agent.religion)\n",
    "        self.agr_bhv = float(agent.agr_bhv)\n",
    "        self.rel_fnt = float(agent.rel_fnt)\n",
    "        self.rel_conv = float(agent.rel_conv)\n",
    "        self.hst_twd_for = float(agent.hst_twd_for)\n",
    "        self.lvl_rct_act = float(agent.lvl_rct_act)\n",
    "        self.crt_agr_lvl = float(agent.crt_agr_lvl)\n",
    "        self.prob_threat = 0\n",
    "        self.type = 'Civilian'\n",
    "        \n",
    "    def step(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_tf import DeepQNetwork\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class HiveMindMil(object):\n",
    "    def __init__(self, alpha, gamma, mem_size, n_actions, epsilon, \n",
    "                batch_size, replace_target=5000, input_dims=(1, 4, 1), \n",
    "                q_next_dir='tmp/mil/q_next', q_eval_dir='tmp/mil/q_eval'):\n",
    "        \n",
    "        self.n_actions = n_actions\n",
    "        self.action_space = [ i for i in range(self.n_actions)]\n",
    "        self.gamma = gamma\n",
    "        self.mem_size = mem_size\n",
    "        self.epsilon = epsilon\n",
    "        self.batch_size = batch_size\n",
    "        self.mem_cntr = 0\n",
    "        self. replace_target = replace_target\n",
    "        self.q_next = DeepQNetwork(alpha, n_actions, input_dims=input_dims, \n",
    "                                    name='q_next', chkpt_dir=q_next_dir)\n",
    "        self.q_eval = DeepQNetwork(alpha, n_actions, input_dims=input_dims,\n",
    "                                    name='q_eval', chkpt_dir=q_eval_dir)\n",
    "        self.state_memory = np.zeros((self.mem_size, *input_dims))\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *input_dims))\n",
    "        self.action_memory = np.zeros((self.mem_size, self.n_actions), dtype=np.int8)\n",
    "        self.reward_memory = np.zeros(self.mem_size)\n",
    "        \n",
    "    def store_transition(self, state, action, reward, state_):\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "        self.state_memory[index] = state\n",
    "        actions = np.zeros(self.n_actions)\n",
    "        actions[action] = 1.0\n",
    "        self.action_memory[index] = actions\n",
    "        self.reward_memory[index] = reward\n",
    "        self.new_state_memory[index] = state_\n",
    "        \n",
    "        self.mem_cntr += 1\n",
    "        \n",
    "    def choose_action(self, state):\n",
    "        rand = np.random.random()\n",
    "        if rand < self.epsilon:\n",
    "            action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            actions = self.q_eval.sess.run(self.q_eval.Q_values,\n",
    "                        feed_dict={self.q_eval.input: state})\n",
    "            action = np.argmax(actions)\n",
    "        return action\n",
    "        \n",
    "    def learn(self):\n",
    "        if self.mem_cntr % self.replace_target == 0:\n",
    "            self.update_graph()\n",
    "        max_mem = self.mem_cntr if self.mem_cntr < self.mem_size else self.mem_size\n",
    "        batch = np.random.choice(max_mem, self.batch_size)\n",
    "        state_batch = self.state_memory[batch]\n",
    "        action_batch = self.action_memory[batch]\n",
    "        action_values = np.array([0, 1, 2, 3], dtype=np.int8)\n",
    "        action_indices = np.dot(action_batch, action_values)\n",
    "        reward_batch = self.reward_memory[batch]\n",
    "        new_state_batch = self.new_state_memory[batch]\n",
    "        \n",
    "        q_eval = self.q_eval.sess.run(self.q_eval.Q_values,\n",
    "                            feed_dict={self.q_eval.input: state_batch})\n",
    "        q_next = self.q_next.sess.run(self.q_next.Q_values,\n",
    "                            feed_dict={self.q_next.input: new_state_batch})\n",
    "                            \n",
    "        q_target = q_eval.copy()\n",
    "        q_target[:, action_indices] = reward_batch + \\\n",
    "                self.gamma*np.max(q_next, axis=1)\n",
    "                \n",
    "        _ = self.q_eval.sess.run(self.q_eval.train_op,\n",
    "                                feed_dict={self.q_eval.input: state_batch,\n",
    "                                            self.q_eval.actions: action_batch,\n",
    "                                            self.q_eval.q_target: q_target})\n",
    "                                            \n",
    "        if self.mem_cntr > 10000:\n",
    "            if self.epsilon > 0.05:\n",
    "                self.epsilon -= 4e-7\n",
    "            elif self.epsilon <= 0.05:\n",
    "                self.epsilon = 0.05\n",
    "                \n",
    "    def save_models(self):\n",
    "        self.q_eval.save_checkpoint()\n",
    "        self.q_next.save_checkpoint()\n",
    "        \n",
    "    def load_models(self):\n",
    "        self.q_eval.load_checkpoint()\n",
    "        self.q_next.load_checkpoint()\n",
    "        \n",
    "    def update_graph(self):\n",
    "        t_params = self.q_next.params\n",
    "        e_params = self.q_eval.params\n",
    "        \n",
    "        for t, e, in zip (t_params, e_params):\n",
    "            self.q_eval.sess.run(tf.assign(t,e))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_tf import DeepQNetwork\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class HiveMindTer(object):\n",
    "    def __init__(self, alpha, gamma, mem_size, n_actions, epsilon, \n",
    "                batch_size, replace_target=5000, input_dims=(1, 15, 1), \n",
    "                q_next_dir='tmp/ter/q_next', q_eval_dir='tmp/ter/q_eval'):\n",
    "        \n",
    "        self.n_actions = n_actions\n",
    "        self.action_space = [ i for i in range(self.n_actions)]\n",
    "        self.gamma = gamma\n",
    "        self.mem_size = mem_size\n",
    "        self.epsilon = epsilon\n",
    "        self.batch_size = batch_size\n",
    "        self.mem_cntr = 0\n",
    "        self. replace_target = replace_target\n",
    "        self.q_next = DeepQNetwork(alpha, n_actions, input_dims=input_dims, \n",
    "                                    name='ter_q_next', chkpt_dir=q_next_dir)\n",
    "        self.q_eval = DeepQNetwork(alpha, n_actions, input_dims=input_dims,\n",
    "                                    name='ter_q_eval', chkpt_dir=q_eval_dir)\n",
    "        self.state_memory = np.zeros((self.mem_size, *input_dims))\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *input_dims))\n",
    "        self.action_memory = np.zeros((self.mem_size, self.n_actions), dtype=np.int8)\n",
    "        self.reward_memory = np.zeros(self.mem_size)\n",
    "        \n",
    "    def store_transition(self, state, action, reward, state_):\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "        self.state_memory[index] = state\n",
    "        actions = np.zeros(self.n_actions)\n",
    "        actions[action] = 1.0\n",
    "        self.action_memory[index] = actions\n",
    "        self.reward_memory[index] = reward\n",
    "        self.new_state_memory[index] = state_\n",
    "        \n",
    "        self.mem_cntr += 1\n",
    "        \n",
    "    def choose_action(self, state):\n",
    "        rand = np.random.random()\n",
    "        if rand < self.epsilon:\n",
    "            action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            actions = self.q_eval.sess.run(self.q_eval.Q_values,\n",
    "                        feed_dict={self.q_eval.input: state})\n",
    "            action = np.argmax(actions)\n",
    "        return action\n",
    "        \n",
    "    def learn(self):\n",
    "        if self.mem_cntr % self.replace_target == 0:\n",
    "            self.update_graph()\n",
    "        max_mem = self.mem_cntr if self.mem_cntr < self.mem_size else self.mem_size\n",
    "        batch = np.random.choice(max_mem, self.batch_size)\n",
    "        state_batch = self.state_memory[batch]\n",
    "        action_batch = self.action_memory[batch]\n",
    "        action_values = np.array([0, 1, 2, 3, 4], dtype=np.int8)\n",
    "        action_indices = np.dot(action_batch, action_values)\n",
    "        reward_batch = self.reward_memory[batch]\n",
    "        new_state_batch = self.new_state_memory[batch]\n",
    "        \n",
    "        q_eval = self.q_eval.sess.run(self.q_eval.Q_values,\n",
    "                            feed_dict={self.q_eval.input: state_batch})\n",
    "        q_next = self.q_next.sess.run(self.q_next.Q_values,\n",
    "                            feed_dict={self.q_next.input: new_state_batch})\n",
    "                            \n",
    "        q_target = q_eval.copy()\n",
    "        q_target[:, action_indices] = reward_batch + \\\n",
    "                self.gamma*np.max(q_next, axis=1)\n",
    "                \n",
    "        _ = self.q_eval.sess.run(self.q_eval.train_op,\n",
    "                                feed_dict={self.q_eval.input: state_batch,\n",
    "                                            self.q_eval.actions: action_batch,\n",
    "                                            self.q_eval.q_target: q_target})\n",
    "                                            \n",
    "        if self.mem_cntr > 10000:\n",
    "            if self.epsilon > 0.05:\n",
    "                self.epsilon -= 4e-7\n",
    "            elif self.epsilon <= 0.05:\n",
    "                self.epsilon = 0.05\n",
    "                \n",
    "    def save_models(self):\n",
    "        self.q_eval.save_checkpoint()\n",
    "        self.q_next.save_checkpoint()\n",
    "        \n",
    "    def load_models(self):\n",
    "        self.q_eval.load_checkpoint()\n",
    "        self.q_next.load_checkpoint()\n",
    "        \n",
    "    def update_graph(self):\n",
    "        t_params = self.q_next.params\n",
    "        e_params = self.q_eval.params\n",
    "        \n",
    "        for t, e, in zip (t_params, e_params):\n",
    "            self.q_eval.sess.run(tf.assign(t,e))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa.visualization.ModularVisualization import ModularServer\n",
    "from mesa.visualization.modules import CanvasGrid, ChartModule, TextElement\n",
    "from mesa.visualization.UserParam import UserSettableParameter\n",
    "\n",
    "from model import MapModel\n",
    "\n",
    "class CCountElement(TextElement):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def render(self, model):\n",
    "        return \"# of Civilians: \" + str(model.get_agent_count('Civilian')) + \" Civil Score: \" + str(model.civilian_score)\n",
    "        \n",
    "\n",
    "class TCountElement(TextElement):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def render(self, model):\n",
    "        return \"# of Terrorists: \" + str(model.get_agent_count('Terrorist')) + \" Terror Score: \" + str(model.terror_score)\n",
    "        \n",
    "class MCountElement(TextElement):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def render(self, model):\n",
    "        return \"# of Troops: \" + str(model.get_agent_count('Military'))\n",
    "        \n",
    "\n",
    "def get_model_params():\n",
    "\n",
    "    height = None\n",
    "    width = None\n",
    "    \n",
    "    map_size = UserSettableParameter(\"choice\", \"Map size\", value=\"Large\", choices=[\"Small\", \"Medium\", \"Large\"])\n",
    "    if map_size.value == \"Large\":\n",
    "        height = 50\n",
    "        width = 50\n",
    "    elif map_size.value == \"Medium\":\n",
    "        height = 25\n",
    "        width = 25\n",
    "    elif map_size.value == \"Small\":\n",
    "        height = 10\n",
    "        width = 10\n",
    "    density = UserSettableParameter(\"slider\", \"Terrorist density\", 0.25, 0.00, 1.00, 0.25)\n",
    "    troop_size = UserSettableParameter(\"number\", \"Troop size\", 10000)\n",
    "    \n",
    "    model_params = {\"height\": height, \"width\": width, \"density\": density, \"map_size\": map_size, \"troop_size\": troop_size}\n",
    "    return model_params\n",
    "\n",
    "def mapmodel_draw(agent):\n",
    "    \n",
    "    if agent is None:\n",
    "        return\n",
    "    portrayal = {\"Shape\": \"circle\", \"r\": 0.8, \"Filled\": \"true\", \"Layer\": 0}\n",
    "    \n",
    "    if agent.type == \"Terrorist\":\n",
    "        portrayal[\"Color\"] = [\"#FF0000\"]\n",
    "        portrayal[\"stroke_color\"] = \"#000000\"\n",
    "    elif agent.type == \"Civilian\":\n",
    "        portrayal[\"Color\"] = [\"#00ff00\"]\n",
    "        portrayal[\"stroke_color\"] = \"#000000\"\n",
    "    elif agent.type == \"Military\":\n",
    "        portrayal[\"Color\"] = [\"#0000FF\"]\n",
    "        portrayal[\"stroke_color\"] = \"#000000\"\n",
    "    return portrayal\n",
    "\n",
    "model_params = get_model_params()\n",
    "\n",
    "c_count_element = CCountElement()\n",
    "t_count_element = TCountElement()\n",
    "m_count_element = MCountElement()\n",
    "\n",
    "canvas_element = CanvasGrid(mapmodel_draw, model_params[\"height\"], model_params[\"width\"], 500, 500)\n",
    "ter_gamma_chart = ChartModule([{\"Label\": \"Terrorist Epsilon\", \"Color\": \"Red\"}, {\"Label\": \"Military Epsilon\", \"Color\": \"Blue\"}])\n",
    "\n",
    "server = ModularServer(MapModel,\n",
    "                        [canvas_element, c_count_element, t_count_element, m_count_element, ter_gamma_chart],\n",
    "                        \"Terrorist Response\", model_params)\n",
    "                        \n",
    "server.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class DeepQNetwork(object):\n",
    "    def __init__(self, lr, n_actions, name, fc1_dims=256,\n",
    "                 input_dims=(1,13), chkpt_dir='tmp/dqn'):\n",
    "        self.lr = lr\n",
    "        self.name = name\n",
    "        self.n_actions = n_actions\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.chkpt_dir = chkpt_dir\n",
    "        self.input_dims = input_dims\n",
    "        self.sess = tf.Session()\n",
    "        self.build_network()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.checkpoint_file = os.path.join(chkpt_dir, 'deepqnet.ckpt')\n",
    "        self.params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                        scope=self.name)\n",
    "        \n",
    "    def build_network(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.input = tf.placeholder(tf.float32, shape=[None, *self.input_dims],\n",
    "                                        name='inputs')\n",
    "            self.actions = tf.placeholder(tf.float32, shape=[None, self.n_actions],\n",
    "                                        name='action_taken')\n",
    "            self.q_target = tf.placeholder(tf.float32, shape=[None, self.n_actions],\n",
    "                                        name='q_value')\n",
    "            \n",
    "            conv1 = tf.layers.conv2d(inputs=self.input, filters=32,\n",
    "                                    kernel_size=(1,1), strides=4, name='conv1',\n",
    "                kernel_initializer=tf.variance_scaling_initializer(scale=2))\n",
    "            conv1_activated = tf.nn.relu(conv1)\n",
    "            \n",
    "            conv2 = tf.layers.conv2d(inputs=conv1_activated, filters=64,\n",
    "                                    kernel_size=(1,1), strides=2, name='conv2',\n",
    "                kernel_initializer=tf.variance_scaling_initializer(scale=2))\n",
    "            conv2_activated = tf.nn.relu(conv2)\n",
    "            \n",
    "            conv3 = tf.layers.conv2d(inputs=conv2_activated, filters=128, \n",
    "                                    kernel_size=(1,1), strides=1, name='conv3',\n",
    "                kernel_initializer=tf.variance_scaling_initializer(scale=2))\n",
    "            conv3_activated = tf.nn.relu(conv3)\n",
    "            \n",
    "            flat = tf.layers.flatten(conv3_activated)\n",
    "            dense1 = tf.layers.dense(flat, units=self.fc1_dims, activation=tf.nn.relu,\n",
    "                                    kernel_initializer=tf.variance_scaling_initializer(scale=2))\n",
    "            self.Q_values = tf.layers.dense(dense1, units=self.n_actions,\n",
    "                                    kernel_initializer=tf.variance_scaling_initializer(scale=2))\n",
    "            \n",
    "            #self.q = tf.reduce_sum(tf.multiply(self.Q_values, self.actions))\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.Q_values - self.q_target))\n",
    "            \n",
    "            self.train_op = tf.train.AdamOptimizer(self.lr).minimize(self.loss)\n",
    "            \n",
    "    def load_checkpoint(self):\n",
    "            print('... loading checkpoint ...')\n",
    "            self.saver.restore(self.sess, self.checkpoint_file)\n",
    "            \n",
    "    def save_checkpoint(self):\n",
    "            print('... saving checkpoint ...')\n",
    "            self.saver.save(self.sess, self.checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from server import server\n",
    "\n",
    "server.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
