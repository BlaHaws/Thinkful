{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn import ensemble\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer, normalize\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C://duh/Thinkful/Thinkful/Exercises/Medium_AggregatedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audioVersionDurationSec</th>\n",
       "      <th>codeBlock</th>\n",
       "      <th>codeBlockCount</th>\n",
       "      <th>collectionId</th>\n",
       "      <th>createdDate</th>\n",
       "      <th>createdDatetime</th>\n",
       "      <th>firstPublishedDate</th>\n",
       "      <th>firstPublishedDatetime</th>\n",
       "      <th>imageCount</th>\n",
       "      <th>isSubscriptionLocked</th>\n",
       "      <th>...</th>\n",
       "      <th>slug</th>\n",
       "      <th>name</th>\n",
       "      <th>postCount</th>\n",
       "      <th>author</th>\n",
       "      <th>bio</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>usersFollowedByCount</th>\n",
       "      <th>usersFollowedCount</th>\n",
       "      <th>scrappedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>638f418c8464</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>2018-09-18 20:55:34</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>2018-09-18 20:57:03</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>blockchain</td>\n",
       "      <td>Blockchain</td>\n",
       "      <td>265164.0</td>\n",
       "      <td>Anar Babaev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f1ad85af0169</td>\n",
       "      <td>babaevanar</td>\n",
       "      <td>450.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>20181104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>638f418c8464</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>2018-09-18 20:55:34</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>2018-09-18 20:57:03</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>5708.0</td>\n",
       "      <td>Anar Babaev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f1ad85af0169</td>\n",
       "      <td>babaevanar</td>\n",
       "      <td>450.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>20181104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>638f418c8464</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>2018-09-18 20:55:34</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>2018-09-18 20:57:03</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>it</td>\n",
       "      <td>It</td>\n",
       "      <td>3720.0</td>\n",
       "      <td>Anar Babaev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f1ad85af0169</td>\n",
       "      <td>babaevanar</td>\n",
       "      <td>450.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>20181104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>2018-01-07 17:04:37</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>2018-01-07 17:06:29</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>166125.0</td>\n",
       "      <td>George Sykes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93b9e94f08ca</td>\n",
       "      <td>tasty231</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20181104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>2018-01-07 17:04:37</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>2018-01-07 17:06:29</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>robotics</td>\n",
       "      <td>Robotics</td>\n",
       "      <td>9103.0</td>\n",
       "      <td>George Sykes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93b9e94f08ca</td>\n",
       "      <td>tasty231</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20181104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   audioVersionDurationSec codeBlock  codeBlockCount  collectionId  \\\n",
       "0                        0       NaN             0.0  638f418c8464   \n",
       "1                        0       NaN             0.0  638f418c8464   \n",
       "2                        0       NaN             0.0  638f418c8464   \n",
       "3                        0       NaN             0.0           NaN   \n",
       "4                        0       NaN             0.0           NaN   \n",
       "\n",
       "  createdDate      createdDatetime firstPublishedDate firstPublishedDatetime  \\\n",
       "0  2018-09-18  2018-09-18 20:55:34         2018-09-18    2018-09-18 20:57:03   \n",
       "1  2018-09-18  2018-09-18 20:55:34         2018-09-18    2018-09-18 20:57:03   \n",
       "2  2018-09-18  2018-09-18 20:55:34         2018-09-18    2018-09-18 20:57:03   \n",
       "3  2018-01-07  2018-01-07 17:04:37         2018-01-07    2018-01-07 17:06:29   \n",
       "4  2018-01-07  2018-01-07 17:04:37         2018-01-07    2018-01-07 17:06:29   \n",
       "\n",
       "   imageCount  isSubscriptionLocked  ...        slug        name postCount  \\\n",
       "0           1                 False  ...  blockchain  Blockchain  265164.0   \n",
       "1           1                 False  ...     samsung     Samsung    5708.0   \n",
       "2           1                 False  ...          it          It    3720.0   \n",
       "3          13                 False  ...  technology  Technology  166125.0   \n",
       "4          13                 False  ...    robotics    Robotics    9103.0   \n",
       "\n",
       "         author  bio        userId    userName  usersFollowedByCount  \\\n",
       "0   Anar Babaev  NaN  f1ad85af0169  babaevanar                 450.0   \n",
       "1   Anar Babaev  NaN  f1ad85af0169  babaevanar                 450.0   \n",
       "2   Anar Babaev  NaN  f1ad85af0169  babaevanar                 450.0   \n",
       "3  George Sykes  NaN  93b9e94f08ca    tasty231                   6.0   \n",
       "4  George Sykes  NaN  93b9e94f08ca    tasty231                   6.0   \n",
       "\n",
       "   usersFollowedCount scrappedDate  \n",
       "0               404.0     20181104  \n",
       "1               404.0     20181104  \n",
       "2               404.0     20181104  \n",
       "3                22.0     20181104  \n",
       "4                22.0     20181104  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text', 'title', 'author', 'language']]\n",
    "df.drop_duplicates(subset='text', inplace=True)\n",
    "df.drop(df.index[df.language != 'en'], inplace=True)\n",
    "authors = df.author.value_counts()[:10].index.to_list()\n",
    "df = df[df.author.isin(authors)]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How Machine Learning is Revolutionizing Digita...</td>\n",
       "      <td>How Machine Learning is Revolutionizing Digita...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tech &amp; Telecom news — Mar 2, 2018\\nPRODUCTS &amp; ...</td>\n",
       "      <td>Tech &amp; Telecom news — Mar 2, 2018</td>\n",
       "      <td>C Gavilanes</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI Biweekly: 10 Bits from May W3 — May W4\\n\\n\\...</td>\n",
       "      <td>AI Biweekly: 10 Bits from May W3 — May W4</td>\n",
       "      <td>Synced</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pittsburgh’s Pivot to Artificial Intelligence\\...</td>\n",
       "      <td>Pittsburgh’s Pivot to Artificial Intelligence</td>\n",
       "      <td>Synced</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tech &amp; Telecom news — Jun 14, 2018\\nPRODUCTS &amp;...</td>\n",
       "      <td>Tech &amp; Telecom news — Jun 14, 2018</td>\n",
       "      <td>C Gavilanes</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  How Machine Learning is Revolutionizing Digita...   \n",
       "1  Tech & Telecom news — Mar 2, 2018\\nPRODUCTS & ...   \n",
       "2  AI Biweekly: 10 Bits from May W3 — May W4\\n\\n\\...   \n",
       "3  Pittsburgh’s Pivot to Artificial Intelligence\\...   \n",
       "4  Tech & Telecom news — Jun 14, 2018\\nPRODUCTS &...   \n",
       "\n",
       "                                               title        author language  \n",
       "0  How Machine Learning is Revolutionizing Digita...  Yves Mulkers       en  \n",
       "1                  Tech & Telecom news — Mar 2, 2018   C Gavilanes       en  \n",
       "2          AI Biweekly: 10 Bits from May W3 — May W4        Synced       en  \n",
       "3      Pittsburgh’s Pivot to Artificial Intelligence        Synced       en  \n",
       "4                 Tech & Telecom news — Jun 14, 2018   C Gavilanes       en  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2024, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "df['doc'] = None\n",
    "df['bow'] = None\n",
    "\n",
    "sentences = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>language</th>\n",
       "      <th>doc</th>\n",
       "      <th>bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How Machine Learning is Revolutionizing Digita...</td>\n",
       "      <td>How Machine Learning is Revolutionizing Digita...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tech &amp; Telecom news — Mar 2, 2018\\nPRODUCTS &amp; ...</td>\n",
       "      <td>Tech &amp; Telecom news — Mar 2, 2018</td>\n",
       "      <td>C Gavilanes</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI Biweekly: 10 Bits from May W3 — May W4\\n\\n\\...</td>\n",
       "      <td>AI Biweekly: 10 Bits from May W3 — May W4</td>\n",
       "      <td>Synced</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pittsburgh’s Pivot to Artificial Intelligence\\...</td>\n",
       "      <td>Pittsburgh’s Pivot to Artificial Intelligence</td>\n",
       "      <td>Synced</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tech &amp; Telecom news — Jun 14, 2018\\nPRODUCTS &amp;...</td>\n",
       "      <td>Tech &amp; Telecom news — Jun 14, 2018</td>\n",
       "      <td>C Gavilanes</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  How Machine Learning is Revolutionizing Digita...   \n",
       "1  Tech & Telecom news — Mar 2, 2018\\nPRODUCTS & ...   \n",
       "2  AI Biweekly: 10 Bits from May W3 — May W4\\n\\n\\...   \n",
       "3  Pittsburgh’s Pivot to Artificial Intelligence\\...   \n",
       "4  Tech & Telecom news — Jun 14, 2018\\nPRODUCTS &...   \n",
       "\n",
       "                                               title        author language  \\\n",
       "0  How Machine Learning is Revolutionizing Digita...  Yves Mulkers       en   \n",
       "1                  Tech & Telecom news — Mar 2, 2018   C Gavilanes       en   \n",
       "2          AI Biweekly: 10 Bits from May W3 — May W4        Synced       en   \n",
       "3      Pittsburgh’s Pivot to Artificial Intelligence        Synced       en   \n",
       "4                 Tech & Telecom news — Jun 14, 2018   C Gavilanes       en   \n",
       "\n",
       "    doc   bow  \n",
       "0  None  None  \n",
       "1  None  None  \n",
       "2  None  None  \n",
       "3  None  None  \n",
       "4  None  None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2024, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 250\n",
      "Processing row 500\n",
      "Processing row 750\n",
      "Processing row 1000\n",
      "Processing row 1250\n",
      "Processing row 1500\n",
      "Processing row 1750\n",
      "Processing row 2000\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(df.text)):\n",
    "    if x % 250 == 0:\n",
    "        print(\"Processing row {}\".format(x))\n",
    "    #df.text[x] = re.sub(df.title[x], '', df.text[x])\n",
    "    df.text[x] = df.text[x].lower()\n",
    "    df.text[x] = re.sub('https://*.*?\\\\n', ' ', df.text[x])\n",
    "    df.text[x] = re.sub('http://*.*?\\\\n', ' ', df.text[x])\n",
    "    df.text[x] = re.sub('\\\\n', ' ', df.text[x])\n",
    "    df.text[x] = re.sub('bibliography.*', '', df.text[x])\n",
    "    df.text[x] = re.sub('[%s]' % re.escape(string.punctuation), '', df.text[x])\n",
    "    df.text[x] = re.sub('\\w*\\d\\w*', '', df.text[x])\n",
    "    df.text[x] = re.sub('’', '', df.text[x])\n",
    "    df.text[x] = re.sub('—', ' ', df.text[x])\n",
    "    df.text[x] = re.sub('”', '', df.text[x])\n",
    "    df.text[x] = re.sub('“', '', df.text[x])\n",
    "    df.text[x] = re.sub('‘', '', df.text[x])\n",
    "    df.text[x] = re.sub('€', '', df.text[x])\n",
    "    df.text[x] = re.sub('…', ' ', df.text[x])\n",
    "    df.text[x] = re.sub('\\ \\ ', ' ', df.text[x])\n",
    "    df.text[x] = re.sub('quest ce quune classe concrete google search févr la figure suivante représente nos classes classe animal nous avons bien notre classe mère animal et wwwgoogleie les décorateurs python est un langage de programmation qui nécessite décrire moins de lignes de code que le c ou le c il se veut openclassroomscom objet est une instance de classe google search en programmation orientée objet on appelle instance dune classe un objet avec un comportement et un état tous deux wwwgoogleie classe abstraite google search classe abstraite et interface quest ce quune classe abstraite une classe abstraite est une classe incomplète elle wwwgoogleie creer une classe python google search nov nous allons aussi essayer de comprendre les mécanismes de la programmation orientée objet en python wwwgoogleie première approche des classes python est un langage de programmation qui nécessite décrire moins de lignes de code que le c ou le c il se veut openclassroomscom', '', df.text[x])\n",
    "    df.text[x] = df.text[x].strip()\n",
    "    if df.text[x] == '':\n",
    "        df.drop([x], inplace=True)\n",
    "        df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>language</th>\n",
       "      <th>doc</th>\n",
       "      <th>bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how machine learning is revolutionizing digita...</td>\n",
       "      <td>How Machine Learning is Revolutionizing Digita...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tech telecom news  mar  products services vide...</td>\n",
       "      <td>Tech &amp; Telecom news — Mar 2, 2018</td>\n",
       "      <td>C Gavilanes</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ai biweekly bits from may  may  may  fujitsu a...</td>\n",
       "      <td>AI Biweekly: 10 Bits from May W3 — May W4</td>\n",
       "      <td>Synced</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pittsburghs pivot to artificial intelligence s...</td>\n",
       "      <td>Pittsburgh’s Pivot to Artificial Intelligence</td>\n",
       "      <td>Synced</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tech telecom news  jun  products services vide...</td>\n",
       "      <td>Tech &amp; Telecom news — Jun 14, 2018</td>\n",
       "      <td>C Gavilanes</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  how machine learning is revolutionizing digita...   \n",
       "1  tech telecom news  mar  products services vide...   \n",
       "2  ai biweekly bits from may  may  may  fujitsu a...   \n",
       "3  pittsburghs pivot to artificial intelligence s...   \n",
       "4  tech telecom news  jun  products services vide...   \n",
       "\n",
       "                                               title        author language  \\\n",
       "0  How Machine Learning is Revolutionizing Digita...  Yves Mulkers       en   \n",
       "1                  Tech & Telecom news — Mar 2, 2018   C Gavilanes       en   \n",
       "2          AI Biweekly: 10 Bits from May W3 — May W4        Synced       en   \n",
       "3      Pittsburgh’s Pivot to Artificial Intelligence        Synced       en   \n",
       "4                 Tech & Telecom news — Jun 14, 2018   C Gavilanes       en   \n",
       "\n",
       "    doc   bow  \n",
       "0  None  None  \n",
       "1  None  None  \n",
       "2  None  None  \n",
       "3  None  None  \n",
       "4  None  None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2024, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(df.text)):\n",
    "    df.doc[x] = nlp(df.text[x])\n",
    "    sents = [[sent, df.author[x]] for sent in df.doc[x]]\n",
    "    sentences = sentences.append(sents, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(how, machine, learning, is, revolutionizing, ...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(then, you, can, not, afford, to, wait, for, t...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(ai, and, machine, learning, ml, machines, tha...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(cognitive, functions, are, still, a, dream, o...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(ml, mimics, how, the, human, cognitive, syste...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0             1\n",
       "0  (how, machine, learning, is, revolutionizing, ...  Yves Mulkers\n",
       "1  (then, you, can, not, afford, to, wait, for, t...  Yves Mulkers\n",
       "2  (ai, and, machine, learning, ml, machines, tha...  Yves Mulkers\n",
       "3  (cognitive, functions, are, still, a, dream, o...  Yves Mulkers\n",
       "4  (ml, mimics, how, the, human, cognitive, syste...  Yves Mulkers"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1108989, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(how, machine, learning, is, revolutionizing, ...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(then, you, can, not, afford, to, wait, for, t...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(ai, and, machine, learning, ml, machines, tha...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(cognitive, functions, are, still, a, dream, o...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(ml, mimics, how, the, human, cognitive, syste...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(the, ml, data, analysis, is, based, on, the, ...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(they, now, beat, us, at, games, like, chess, ...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(they, can, recognize, images, more, accuratel...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(technology, let, us, look, at, some, examples...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(this, experience, might, be, taken, to, new, ...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(ie, chatbots)</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(initially, they, will, be, a, part, of, the, ...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(ml, technology, does, not, force, the, user, ...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(tech, telecom, news,  , mar,  , products, ser...</td>\n",
       "      <td>C Gavilanes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(just, published, results, beating, analysts, ...</td>\n",
       "      <td>C Gavilanes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(eu, regulators, increasing, pressure, on, int...</td>\n",
       "      <td>C Gavilanes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(ai, biweekly, bits, from, may,  , may,  , may...</td>\n",
       "      <td>Synced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(real, estate, launches, ai, website, for, con...</td>\n",
       "      <td>Synced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(deep, learningdriven, nlp)</td>\n",
       "      <td>Synced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(library, intel, ai, lab, opensources, a, natu...</td>\n",
       "      <td>Synced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(pittsburghs, pivot, to, artificial, intellige...</td>\n",
       "      <td>Synced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(institute, nine, years, later, the, institute...</td>\n",
       "      <td>Synced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(the, robotics, institute, has, faculty, membe...</td>\n",
       "      <td>Synced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(i, remember, allen, newell, saying, to, us, i...</td>\n",
       "      <td>Synced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(she, also, helped, launch, the, robocup, init...</td>\n",
       "      <td>Synced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(it, will, be, more, and, more, present, in, o...</td>\n",
       "      <td>Synced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(but, i, do, nt, call, it, hci)</td>\n",
       "      <td>Synced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(says, professor, veloso, its, humanai, intera...</td>\n",
       "      <td>Synced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(she, says, the, requirements, proposed, by, h...</td>\n",
       "      <td>Synced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(a, phd, student, really, means, working, but,...</td>\n",
       "      <td>Synced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108959</th>\n",
       "      <td>down</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108960</th>\n",
       "      <td>the</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108961</th>\n",
       "      <td>analytic</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108962</th>\n",
       "      <td>process</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108963</th>\n",
       "      <td>developed</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108964</th>\n",
       "      <td>by</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108965</th>\n",
       "      <td>our</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108966</th>\n",
       "      <td>crewmates</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108967</th>\n",
       "      <td>at</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108968</th>\n",
       "      <td>corsairs</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108969</th>\n",
       "      <td>institute</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108970</th>\n",
       "      <td>our</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108971</th>\n",
       "      <td>subscribe</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108972</th>\n",
       "      <td>to</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108973</th>\n",
       "      <td>corsairs</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108974</th>\n",
       "      <td>network</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108975</th>\n",
       "      <td>today</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108976</th>\n",
       "      <td>the</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108977</th>\n",
       "      <td>worlds</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108978</th>\n",
       "      <td>fastest</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108979</th>\n",
       "      <td>growing</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108980</th>\n",
       "      <td>analytic</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108981</th>\n",
       "      <td>network</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108982</th>\n",
       "      <td>provides</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108983</th>\n",
       "      <td>thoughtprovoking</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108984</th>\n",
       "      <td>and</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108985</th>\n",
       "      <td>entertaining</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108986</th>\n",
       "      <td>content</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108987</th>\n",
       "      <td>reading</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108988</th>\n",
       "      <td>registercorsairsnetwork</td>\n",
       "      <td>Corsair's Publishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1108989 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0  \\\n",
       "0        (how, machine, learning, is, revolutionizing, ...   \n",
       "1        (then, you, can, not, afford, to, wait, for, t...   \n",
       "2        (ai, and, machine, learning, ml, machines, tha...   \n",
       "3        (cognitive, functions, are, still, a, dream, o...   \n",
       "4        (ml, mimics, how, the, human, cognitive, syste...   \n",
       "5        (the, ml, data, analysis, is, based, on, the, ...   \n",
       "6        (they, now, beat, us, at, games, like, chess, ...   \n",
       "7        (they, can, recognize, images, more, accuratel...   \n",
       "8        (technology, let, us, look, at, some, examples...   \n",
       "9        (this, experience, might, be, taken, to, new, ...   \n",
       "10                                          (ie, chatbots)   \n",
       "11       (initially, they, will, be, a, part, of, the, ...   \n",
       "12       (ml, technology, does, not, force, the, user, ...   \n",
       "13       (tech, telecom, news,  , mar,  , products, ser...   \n",
       "14       (just, published, results, beating, analysts, ...   \n",
       "15       (eu, regulators, increasing, pressure, on, int...   \n",
       "16       (ai, biweekly, bits, from, may,  , may,  , may...   \n",
       "17       (real, estate, launches, ai, website, for, con...   \n",
       "18                             (deep, learningdriven, nlp)   \n",
       "19       (library, intel, ai, lab, opensources, a, natu...   \n",
       "20       (pittsburghs, pivot, to, artificial, intellige...   \n",
       "21       (institute, nine, years, later, the, institute...   \n",
       "22       (the, robotics, institute, has, faculty, membe...   \n",
       "23       (i, remember, allen, newell, saying, to, us, i...   \n",
       "24       (she, also, helped, launch, the, robocup, init...   \n",
       "25       (it, will, be, more, and, more, present, in, o...   \n",
       "26                         (but, i, do, nt, call, it, hci)   \n",
       "27       (says, professor, veloso, its, humanai, intera...   \n",
       "28       (she, says, the, requirements, proposed, by, h...   \n",
       "29       (a, phd, student, really, means, working, but,...   \n",
       "...                                                    ...   \n",
       "1108959                                               down   \n",
       "1108960                                                the   \n",
       "1108961                                           analytic   \n",
       "1108962                                            process   \n",
       "1108963                                          developed   \n",
       "1108964                                                 by   \n",
       "1108965                                                our   \n",
       "1108966                                          crewmates   \n",
       "1108967                                                 at   \n",
       "1108968                                           corsairs   \n",
       "1108969                                          institute   \n",
       "1108970                                                our   \n",
       "1108971                                          subscribe   \n",
       "1108972                                                 to   \n",
       "1108973                                           corsairs   \n",
       "1108974                                            network   \n",
       "1108975                                              today   \n",
       "1108976                                                the   \n",
       "1108977                                             worlds   \n",
       "1108978                                            fastest   \n",
       "1108979                                            growing   \n",
       "1108980                                           analytic   \n",
       "1108981                                            network   \n",
       "1108982                                           provides   \n",
       "1108983                                   thoughtprovoking   \n",
       "1108984                                                and   \n",
       "1108985                                       entertaining   \n",
       "1108986                                            content   \n",
       "1108987                                            reading   \n",
       "1108988                            registercorsairsnetwork   \n",
       "\n",
       "                            1  \n",
       "0                Yves Mulkers  \n",
       "1                Yves Mulkers  \n",
       "2                Yves Mulkers  \n",
       "3                Yves Mulkers  \n",
       "4                Yves Mulkers  \n",
       "5                Yves Mulkers  \n",
       "6                Yves Mulkers  \n",
       "7                Yves Mulkers  \n",
       "8                Yves Mulkers  \n",
       "9                Yves Mulkers  \n",
       "10               Yves Mulkers  \n",
       "11               Yves Mulkers  \n",
       "12               Yves Mulkers  \n",
       "13                C Gavilanes  \n",
       "14                C Gavilanes  \n",
       "15                C Gavilanes  \n",
       "16                     Synced  \n",
       "17                     Synced  \n",
       "18                     Synced  \n",
       "19                     Synced  \n",
       "20                     Synced  \n",
       "21                     Synced  \n",
       "22                     Synced  \n",
       "23                     Synced  \n",
       "24                     Synced  \n",
       "25                     Synced  \n",
       "26                     Synced  \n",
       "27                     Synced  \n",
       "28                     Synced  \n",
       "29                     Synced  \n",
       "...                       ...  \n",
       "1108959  Corsair's Publishing  \n",
       "1108960  Corsair's Publishing  \n",
       "1108961  Corsair's Publishing  \n",
       "1108962  Corsair's Publishing  \n",
       "1108963  Corsair's Publishing  \n",
       "1108964  Corsair's Publishing  \n",
       "1108965  Corsair's Publishing  \n",
       "1108966  Corsair's Publishing  \n",
       "1108967  Corsair's Publishing  \n",
       "1108968  Corsair's Publishing  \n",
       "1108969  Corsair's Publishing  \n",
       "1108970  Corsair's Publishing  \n",
       "1108971  Corsair's Publishing  \n",
       "1108972  Corsair's Publishing  \n",
       "1108973  Corsair's Publishing  \n",
       "1108974  Corsair's Publishing  \n",
       "1108975  Corsair's Publishing  \n",
       "1108976  Corsair's Publishing  \n",
       "1108977  Corsair's Publishing  \n",
       "1108978  Corsair's Publishing  \n",
       "1108979  Corsair's Publishing  \n",
       "1108980  Corsair's Publishing  \n",
       "1108981  Corsair's Publishing  \n",
       "1108982  Corsair's Publishing  \n",
       "1108983  Corsair's Publishing  \n",
       "1108984  Corsair's Publishing  \n",
       "1108985  Corsair's Publishing  \n",
       "1108986  Corsair's Publishing  \n",
       "1108987  Corsair's Publishing  \n",
       "1108988  Corsair's Publishing  \n",
       "\n",
       "[1108989 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(text):\n",
    "    \n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    return [item[0] for item in Counter(allwords).most_common(25)]\n",
    "    \n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(df.text)):\n",
    "    df.bow[x] = bag_of_words(df.doc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>language</th>\n",
       "      <th>doc</th>\n",
       "      <th>bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how machine learning is revolutionizing digita...</td>\n",
       "      <td>How Machine Learning is Revolutionizing Digita...</td>\n",
       "      <td>Yves Mulkers</td>\n",
       "      <td>en</td>\n",
       "      <td>(how, machine, learning, is, revolutionizing, ...</td>\n",
       "      <td>[ml, business, machine, technology, datum, ent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tech telecom news  mar  products services vide...</td>\n",
       "      <td>Tech &amp; Telecom news — Mar 2, 2018</td>\n",
       "      <td>C Gavilanes</td>\n",
       "      <td>en</td>\n",
       "      <td>(tech, telecom, news,  , mar,  , products, ser...</td>\n",
       "      <td>[story, new, app, company, mobile, service, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ai biweekly bits from may  may  may  fujitsu a...</td>\n",
       "      <td>AI Biweekly: 10 Bits from May W3 — May W4</td>\n",
       "      <td>Synced</td>\n",
       "      <td>en</td>\n",
       "      <td>(ai, biweekly, bits, from, may,  , may,  , may...</td>\n",
       "      <td>[ai,  , intel, centre, develop, library, solut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pittsburghs pivot to artificial intelligence s...</td>\n",
       "      <td>Pittsburgh’s Pivot to Artificial Intelligence</td>\n",
       "      <td>Synced</td>\n",
       "      <td>en</td>\n",
       "      <td>(pittsburghs, pivot, to, artificial, intellige...</td>\n",
       "      <td>[professor, robotic, robot, pittsburgh, year, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tech telecom news  jun  products services vide...</td>\n",
       "      <td>Tech &amp; Telecom news — Jun 14, 2018</td>\n",
       "      <td>C Gavilanes</td>\n",
       "      <td>en</td>\n",
       "      <td>(tech, telecom, news,  , jun,  , products, ser...</td>\n",
       "      <td>[story, app, new, announce, service, video, ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  how machine learning is revolutionizing digita...   \n",
       "1  tech telecom news  mar  products services vide...   \n",
       "2  ai biweekly bits from may  may  may  fujitsu a...   \n",
       "3  pittsburghs pivot to artificial intelligence s...   \n",
       "4  tech telecom news  jun  products services vide...   \n",
       "\n",
       "                                               title        author language  \\\n",
       "0  How Machine Learning is Revolutionizing Digita...  Yves Mulkers       en   \n",
       "1                  Tech & Telecom news — Mar 2, 2018   C Gavilanes       en   \n",
       "2          AI Biweekly: 10 Bits from May W3 — May W4        Synced       en   \n",
       "3      Pittsburgh’s Pivot to Artificial Intelligence        Synced       en   \n",
       "4                 Tech & Telecom news — Jun 14, 2018   C Gavilanes       en   \n",
       "\n",
       "                                                 doc  \\\n",
       "0  (how, machine, learning, is, revolutionizing, ...   \n",
       "1  (tech, telecom, news,  , mar,  , products, ser...   \n",
       "2  (ai, biweekly, bits, from, may,  , may,  , may...   \n",
       "3  (pittsburghs, pivot, to, artificial, intellige...   \n",
       "4  (tech, telecom, news,  , jun,  , products, ser...   \n",
       "\n",
       "                                                 bow  \n",
       "0  [ml, business, machine, technology, datum, ent...  \n",
       "1  [story, new, app, company, mobile, service, an...  \n",
       "2  [ai,  , intel, centre, develop, library, solut...  \n",
       "3  [professor, robotic, robot, pittsburgh, year, ...  \n",
       "4  [story, app, new, announce, service, video, ga...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = set()\n",
    "for x in range(len(df.text)):\n",
    "    common_words.update(df.bow[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       {human, technology, include, learning, machine...\n",
       "1       {claim, revenue, disney,  , authentication, ne...\n",
       "2       {million, develop, cancer, launch, technology,...\n",
       "3       {company, pittsburgh, say, work, machine, cent...\n",
       "4       {operator, time, week, tv, stock, build,  , ne...\n",
       "5       {heatmap, lab, train, brain, sample, google, m...\n",
       "6       {file, stackoverflowcom, create, powershell, a...\n",
       "7       {tencent, amazon, human, unemployment, work, t...\n",
       "8       {failure, human, production, rethink, chief, e...\n",
       "9       {accord, crucial, lack, marketing, understandi...\n",
       "10      {work, include, machine, learning, figure,  , ...\n",
       "11      {far, baird, police, department, time, platfor...\n",
       "12      {exist, lab, hellermark, time, spot, platform,...\n",
       "13      {operator, cable, result, tmobile, sprint,  , ...\n",
       "14      {sale, human, assistant, soon, think, google, ...\n",
       "15      {doctor, dean, brain, patient, tool, informati...\n",
       "16      {internet, concern, drive, growth, include,  ,...\n",
       "17      {failure, iot, say, time, pool, machine, predi...\n",
       "18      {scene,  , learn, webography, chapter, dummy, ...\n",
       "19      {time, week, autonomous, stock, growth, online...\n",
       "20      {business, better, piktochart, learn, ml, edit...\n",
       "21      {million, company, china, iot, technology, uni...\n",
       "22      {unmanned, autonomous, technology, power, denv...\n",
       "23      {lab, nyu, ross, gap, program,  , series, new,...\n",
       "24      {time, type, work, kpis, ensure, business, rig...\n",
       "25      {scene, machinelearningmasterycom, reframing, ...\n",
       "26      {emerge, far, iot, trend, public, information,...\n",
       "27      {million, china, active, globally, taotiao, gl...\n",
       "28      {michelangelo, uber, balso, page, platform, ma...\n",
       "29      {monitor, platform, autonomous, technology, po...\n",
       "                              ...                        \n",
       "1994    {gift, cream, go, young, blind, life, analytic...\n",
       "1995    {character, profile, time, provide, dealer, re...\n",
       "1996    {propagation, february, outperform, graph, plo...\n",
       "1997    {propagation, gif, go, leave, google, original...\n",
       "1998    {loss, train, propose, author, segmentation, g...\n",
       "1999    {study, readmission, result, patient, learning...\n",
       "2000    {replay, june, layer, train, create, reinforce...\n",
       "2001    {polyp, study, colorectal, detection, evidence...\n",
       "2002    {circle, layer, recurrent, time, google, pixel...\n",
       "2003    {loss, discrepancy, train, mav, knowledge, hum...\n",
       "2004    {injection, give, encode, caption, generation,...\n",
       "2005    {simplify, far, time, simplification, human, b...\n",
       "2006    {general, component, average, june, time, tren...\n",
       "2007    {activation, layer, train, tanh, retrieve, aut...\n",
       "2008    {general, analyze, care, patient, healthcare, ...\n",
       "2009    {derivative, june, simple, go, probability, le...\n",
       "2010    {date, create, go, human, work, think, power, ...\n",
       "2011    {feedback, big, industry, analytic,  , point, ...\n",
       "2012    {costume, provide, makeup, read, play, think, ...\n",
       "2013    {pillar, provide, strong, live, probability, p...\n",
       "2014    {circle, recurrent, layer, time, train, lag, r...\n",
       "2015    {derivative, layer, soften, encoder, leave, re...\n",
       "2016    {create, develop, provide, technology, feedbac...\n",
       "2017    {comedy, far, senate, recognize, literacy, rea...\n",
       "2018    {generative, give, encoder, match, sample, aut...\n",
       "2019    {propagation, train, think, google, perform,  ...\n",
       "2020    {train, encoder, unlabeled, face, human, learn...\n",
       "2021    {far, analyze, provide, certainly, people, all...\n",
       "2022    {half, popper, lord, history, create, provide,...\n",
       "2023    {thinking, iteration, think, yes,  , analytic,...\n",
       "Name: bow, Length: 2024, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-3928f1ef739d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbow_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommon_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-1b029449c7c6>\u001b[0m in \u001b[0;36mbow_features\u001b[1;34m(sentences, common_words)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_sentence'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_source'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommon_words\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_sentence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blaine\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blaine\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blaine\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_tuple\u001b[1;34m(self, key, is_setter)\u001b[0m\n\u001b[0;32m    246\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Too many indexers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m                 \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_setter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m                 \u001b[0mkeyidx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyidx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blaine\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[0;32m   1353\u001b[0m                           raise_missing}\n\u001b[1;32m-> 1354\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blaine\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1147\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m             \u001b[1;31m# If we are trying to get actual keys from empty Series, we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;31m# patiently wait for a KeyError later on - otherwise, convert\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blaine\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mis_unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1661\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mhas\u001b[0m \u001b[0munique\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1662\u001b[0m         \"\"\"\n\u001b[1;32m-> 1663\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1665\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.is_unique.__get__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._do_unique_check\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._ensure_mapping_populated\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._call_map_locations\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.map_locations\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'set'"
     ]
    }
   ],
   "source": [
    "word_counts = bow_features(sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_norm = normalize(X)\n",
    "\n",
    "#pca = PCA(.95)\n",
    "#X_pca = pca.fit_transform(X_norm)\n",
    "\n",
    "svd= TruncatedSVD(10)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_lsa = lsa.fit_transform(X)\n",
    "\n",
    "# Calculate predicted values.\n",
    "y_pred = KMeans(random_state=0).fit_predict(X_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(X_lsa[:, 0], X_lsa[:, 1], c=word_counts.text_source.drop_duplicates())\n",
    "plt.scatter(X_lsa[:, 2], X_lsa[:, 3], c=y_pred)\n",
    "plt.scatter(X_lsa[:, 4], X_lsa[:, 5], c=y_pred)\n",
    "plt.scatter(X_lsa[:, 6], X_lsa[:, 7], c=y_pred)\n",
    "plt.scatter(X_lsa[:, 8], X_lsa[:, 9], c=y_pred)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "        \n",
    "print('Training score: ', lr.score(X_train, y_train))\n",
    "print('Test score: ', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear')\n",
    "train = svm.fit(X_train, y_train)\n",
    "\n",
    "print('Training score: ', svm.score(X_train, y_train))\n",
    "print('Test score: ', svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
