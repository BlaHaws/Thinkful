{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn import ensemble\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer, normalize\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C://duh/Thinkful/Thinkful/Exercises/Medium_AggregatedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audioVersionDurationSec</th>\n",
       "      <th>codeBlock</th>\n",
       "      <th>codeBlockCount</th>\n",
       "      <th>collectionId</th>\n",
       "      <th>createdDate</th>\n",
       "      <th>createdDatetime</th>\n",
       "      <th>firstPublishedDate</th>\n",
       "      <th>firstPublishedDatetime</th>\n",
       "      <th>imageCount</th>\n",
       "      <th>isSubscriptionLocked</th>\n",
       "      <th>...</th>\n",
       "      <th>slug</th>\n",
       "      <th>name</th>\n",
       "      <th>postCount</th>\n",
       "      <th>author</th>\n",
       "      <th>bio</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>usersFollowedByCount</th>\n",
       "      <th>usersFollowedCount</th>\n",
       "      <th>scrappedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>638f418c8464</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>2018-09-18 20:55:34</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>2018-09-18 20:57:03</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>blockchain</td>\n",
       "      <td>Blockchain</td>\n",
       "      <td>265164.0</td>\n",
       "      <td>Anar Babaev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f1ad85af0169</td>\n",
       "      <td>babaevanar</td>\n",
       "      <td>450.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>20181104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>638f418c8464</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>2018-09-18 20:55:34</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>2018-09-18 20:57:03</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>5708.0</td>\n",
       "      <td>Anar Babaev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f1ad85af0169</td>\n",
       "      <td>babaevanar</td>\n",
       "      <td>450.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>20181104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>638f418c8464</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>2018-09-18 20:55:34</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>2018-09-18 20:57:03</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>it</td>\n",
       "      <td>It</td>\n",
       "      <td>3720.0</td>\n",
       "      <td>Anar Babaev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f1ad85af0169</td>\n",
       "      <td>babaevanar</td>\n",
       "      <td>450.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>20181104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>2018-01-07 17:04:37</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>2018-01-07 17:06:29</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>166125.0</td>\n",
       "      <td>George Sykes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93b9e94f08ca</td>\n",
       "      <td>tasty231</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20181104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>2018-01-07 17:04:37</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>2018-01-07 17:06:29</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>robotics</td>\n",
       "      <td>Robotics</td>\n",
       "      <td>9103.0</td>\n",
       "      <td>George Sykes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93b9e94f08ca</td>\n",
       "      <td>tasty231</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20181104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   audioVersionDurationSec codeBlock  codeBlockCount  collectionId  \\\n",
       "0                        0       NaN             0.0  638f418c8464   \n",
       "1                        0       NaN             0.0  638f418c8464   \n",
       "2                        0       NaN             0.0  638f418c8464   \n",
       "3                        0       NaN             0.0           NaN   \n",
       "4                        0       NaN             0.0           NaN   \n",
       "\n",
       "  createdDate      createdDatetime firstPublishedDate firstPublishedDatetime  \\\n",
       "0  2018-09-18  2018-09-18 20:55:34         2018-09-18    2018-09-18 20:57:03   \n",
       "1  2018-09-18  2018-09-18 20:55:34         2018-09-18    2018-09-18 20:57:03   \n",
       "2  2018-09-18  2018-09-18 20:55:34         2018-09-18    2018-09-18 20:57:03   \n",
       "3  2018-01-07  2018-01-07 17:04:37         2018-01-07    2018-01-07 17:06:29   \n",
       "4  2018-01-07  2018-01-07 17:04:37         2018-01-07    2018-01-07 17:06:29   \n",
       "\n",
       "   imageCount  isSubscriptionLocked  ...        slug        name postCount  \\\n",
       "0           1                 False  ...  blockchain  Blockchain  265164.0   \n",
       "1           1                 False  ...     samsung     Samsung    5708.0   \n",
       "2           1                 False  ...          it          It    3720.0   \n",
       "3          13                 False  ...  technology  Technology  166125.0   \n",
       "4          13                 False  ...    robotics    Robotics    9103.0   \n",
       "\n",
       "         author  bio        userId    userName  usersFollowedByCount  \\\n",
       "0   Anar Babaev  NaN  f1ad85af0169  babaevanar                 450.0   \n",
       "1   Anar Babaev  NaN  f1ad85af0169  babaevanar                 450.0   \n",
       "2   Anar Babaev  NaN  f1ad85af0169  babaevanar                 450.0   \n",
       "3  George Sykes  NaN  93b9e94f08ca    tasty231                   6.0   \n",
       "4  George Sykes  NaN  93b9e94f08ca    tasty231                   6.0   \n",
       "\n",
       "   usersFollowedCount scrappedDate  \n",
       "0               404.0     20181104  \n",
       "1               404.0     20181104  \n",
       "2               404.0     20181104  \n",
       "3                22.0     20181104  \n",
       "4                22.0     20181104  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text', 'title', 'author', 'language']]\n",
    "df.drop(df.index[df.language != 'en'], inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "authorindex = []\n",
    "for author in df.author.unique():\n",
    "    if df.text.where(df.author == author).nunique() >= 100 and df.text.where(df.author == author).nunique() <= 150:\n",
    "        authorindex.append(author)\n",
    "df = df.query('author in @authorindex')\n",
    "df = df.reset_index(drop=True)\n",
    "nlp = spacy.load('en')\n",
    "df['doc'] = None\n",
    "df['bow'] = None\n",
    "\n",
    "del authorindex\n",
    "\n",
    "sentences = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>language</th>\n",
       "      <th>doc</th>\n",
       "      <th>bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It’s Pretty Bleeping Scary.\\nAnd this is Sam H...</td>\n",
       "      <td>It’s Pretty Bleeping Scary.</td>\n",
       "      <td>Peter Marshall</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It’s Pretty Bleeping Scary.\\nAnd this is Sam H...</td>\n",
       "      <td>It’s Pretty Bleeping Scary.</td>\n",
       "      <td>Peter Marshall</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It’s Pretty Bleeping Scary.\\nAnd this is Sam H...</td>\n",
       "      <td>It’s Pretty Bleeping Scary.</td>\n",
       "      <td>Peter Marshall</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Webography for 4 dummies to make it in machine...</td>\n",
       "      <td>Webography for 4 dummies to make it in machine...</td>\n",
       "      <td>WELTARE Strategies</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Webography for 4 dummies to make it in machine...</td>\n",
       "      <td>Webography for 4 dummies to make it in machine...</td>\n",
       "      <td>WELTARE Strategies</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  It’s Pretty Bleeping Scary.\\nAnd this is Sam H...   \n",
       "1  It’s Pretty Bleeping Scary.\\nAnd this is Sam H...   \n",
       "2  It’s Pretty Bleeping Scary.\\nAnd this is Sam H...   \n",
       "3  Webography for 4 dummies to make it in machine...   \n",
       "4  Webography for 4 dummies to make it in machine...   \n",
       "\n",
       "                                               title              author  \\\n",
       "0                        It’s Pretty Bleeping Scary.      Peter Marshall   \n",
       "1                        It’s Pretty Bleeping Scary.      Peter Marshall   \n",
       "2                        It’s Pretty Bleeping Scary.      Peter Marshall   \n",
       "3  Webography for 4 dummies to make it in machine...  WELTARE Strategies   \n",
       "4  Webography for 4 dummies to make it in machine...  WELTARE Strategies   \n",
       "\n",
       "  language   doc   bow  \n",
       "0       en  None  None  \n",
       "1       en  None  None  \n",
       "2       en  None  None  \n",
       "3       en  None  None  \n",
       "4       en  None  None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='text', inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 250\n",
      "Processing row 500\n",
      "Processing row 750\n",
      "Processing row 1000\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(df.text)):\n",
    "    if x % 250 == 0:\n",
    "        print(\"Processing row {}\".format(x))\n",
    "    #df.text[x] = re.sub(df.title[x], '', df.text[x])\n",
    "    df.text[x] = df.text[x].lower()\n",
    "    df.text[x] = re.sub('https://*.*?\\\\n', ' ', df.text[x])\n",
    "    df.text[x] = re.sub('http://*.*?\\\\n', ' ', df.text[x])\n",
    "    df.text[x] = re.sub('\\\\n', ' ', df.text[x])\n",
    "    df.text[x] = re.sub('bibliography.*', '', df.text[x])\n",
    "    df.text[x] = re.sub('[%s]' % re.escape(string.punctuation), '', df.text[x])\n",
    "    df.text[x] = re.sub('\\w*\\d\\w*', '', df.text[x])\n",
    "    df.text[x] = re.sub('’', '', df.text[x])\n",
    "    df.text[x] = re.sub('—', ' ', df.text[x])\n",
    "    df.text[x] = re.sub('”', '', df.text[x])\n",
    "    df.text[x] = re.sub('“', '', df.text[x])\n",
    "    df.text[x] = re.sub('‘', '', df.text[x])\n",
    "    df.text[x] = re.sub('€', '', df.text[x])\n",
    "    df.text[x] = re.sub('…', ' ', df.text[x])\n",
    "    df.text[x] = re.sub('\\ \\ ', ' ', df.text[x])\n",
    "    df.text[x] = re.sub('quest ce quune classe concrete google search févr la figure suivante représente nos classes classe animal nous avons bien notre classe mère animal et wwwgoogleie les décorateurs python est un langage de programmation qui nécessite décrire moins de lignes de code que le c ou le c il se veut openclassroomscom objet est une instance de classe google search en programmation orientée objet on appelle instance dune classe un objet avec un comportement et un état tous deux wwwgoogleie classe abstraite google search classe abstraite et interface quest ce quune classe abstraite une classe abstraite est une classe incomplète elle wwwgoogleie creer une classe python google search nov nous allons aussi essayer de comprendre les mécanismes de la programmation orientée objet en python wwwgoogleie première approche des classes python est un langage de programmation qui nécessite décrire moins de lignes de code que le c ou le c il se veut openclassroomscom', '', df.text[x])\n",
    "    df.text[x] = df.text[x].strip()\n",
    "    if df.text[x] == '':\n",
    "        df.drop([x], inplace=True)\n",
    "        df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>language</th>\n",
       "      <th>doc</th>\n",
       "      <th>bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>its pretty bleeping scary and this is sam harr...</td>\n",
       "      <td>It’s Pretty Bleeping Scary.</td>\n",
       "      <td>Peter Marshall</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>webography for dummies to make it in machine l...</td>\n",
       "      <td>Webography for 4 dummies to make it in machine...</td>\n",
       "      <td>WELTARE Strategies</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>technological unemployment and ubi reutersmura...</td>\n",
       "      <td>Technological Unemployment and UBI</td>\n",
       "      <td>Michael K. Spencer</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vantagepoint forex weekly outlook for march  t...</td>\n",
       "      <td>VantagePoint Forex Weekly Outlook for March 5t...</td>\n",
       "      <td>Vantagepoint ai</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>humanintheloop ai for emergency response more ...</td>\n",
       "      <td>Human-in-the-Loop AI for Emergency Response &amp; ...</td>\n",
       "      <td>TWiML &amp; AI</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  its pretty bleeping scary and this is sam harr...   \n",
       "1  webography for dummies to make it in machine l...   \n",
       "2  technological unemployment and ubi reutersmura...   \n",
       "3  vantagepoint forex weekly outlook for march  t...   \n",
       "4  humanintheloop ai for emergency response more ...   \n",
       "\n",
       "                                               title              author  \\\n",
       "0                        It’s Pretty Bleeping Scary.      Peter Marshall   \n",
       "1  Webography for 4 dummies to make it in machine...  WELTARE Strategies   \n",
       "2                 Technological Unemployment and UBI  Michael K. Spencer   \n",
       "3  VantagePoint Forex Weekly Outlook for March 5t...     Vantagepoint ai   \n",
       "4  Human-in-the-Loop AI for Emergency Response & ...          TWiML & AI   \n",
       "\n",
       "  language   doc   bow  \n",
       "0       en  None  None  \n",
       "1       en  None  None  \n",
       "2       en  None  None  \n",
       "3       en  None  None  \n",
       "4       en  None  None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(df.text)):\n",
    "    df.doc[x] = nlp(df.text[x])\n",
    "    sents = [[sent, df.author[x]] for sent in df.doc[x].sents]\n",
    "    sentences = sentences.append(sents, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(its, pretty, bleeping, scary, and, this, is, ...</td>\n",
       "      <td>Peter Marshall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(and, i, think, he, s, absolutely, right, with...</td>\n",
       "      <td>Peter Marshall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(webography, for, dummies, to, make, it, in, m...</td>\n",
       "      <td>WELTARE Strategies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(what, s, the, difference, with, docker, conta...</td>\n",
       "      <td>WELTARE Strategies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(and, now, i, m, trying, to, create, a, text, ...</td>\n",
       "      <td>WELTARE Strategies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0                   1\n",
       "0  (its, pretty, bleeping, scary, and, this, is, ...      Peter Marshall\n",
       "1  (and, i, think, he, s, absolutely, right, with...      Peter Marshall\n",
       "2  (webography, for, dummies, to, make, it, in, m...  WELTARE Strategies\n",
       "3  (what, s, the, difference, with, docker, conta...  WELTARE Strategies\n",
       "4  (and, now, i, m, trying, to, create, a, text, ...  WELTARE Strategies"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11188, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(text):\n",
    "    \n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(df.text)):\n",
    "    df.bow[x] = bag_of_words(df.doc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>language</th>\n",
       "      <th>doc</th>\n",
       "      <th>bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>its pretty bleeping scary and this is sam harr...</td>\n",
       "      <td>It’s Pretty Bleeping Scary.</td>\n",
       "      <td>Peter Marshall</td>\n",
       "      <td>en</td>\n",
       "      <td>(its, pretty, bleeping, scary, and, this, is, ...</td>\n",
       "      <td>[think, pretty, bleeping, scary, agi, absolute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>webography for dummies to make it in machine l...</td>\n",
       "      <td>Webography for 4 dummies to make it in machine...</td>\n",
       "      <td>WELTARE Strategies</td>\n",
       "      <td>en</td>\n",
       "      <td>(webography, for, dummies, to, make, it, in, m...</td>\n",
       "      <td>[create, file, touch, powershell, linux, langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>technological unemployment and ubi reutersmura...</td>\n",
       "      <td>Technological Unemployment and UBI</td>\n",
       "      <td>Michael K. Spencer</td>\n",
       "      <td>en</td>\n",
       "      <td>(technological, unemployment, and, ubi, reuter...</td>\n",
       "      <td>[technological, human, amazon, world, robot, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vantagepoint forex weekly outlook for march  t...</td>\n",
       "      <td>VantagePoint Forex Weekly Outlook for March 5t...</td>\n",
       "      <td>Vantagepoint ai</td>\n",
       "      <td>en</td>\n",
       "      <td>(vantagepoint, forex, weekly, outlook, for, ma...</td>\n",
       "      <td>[level, key, vantagepoint, market, pair, movem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>humanintheloop ai for emergency response more ...</td>\n",
       "      <td>Human-in-the-Loop AI for Emergency Response &amp; ...</td>\n",
       "      <td>TWiML &amp; AI</td>\n",
       "      <td>en</td>\n",
       "      <td>(humanintheloop, ai, for, emergency, response,...</td>\n",
       "      <td>[figure, ai, twiml, machine, learning, rob, le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  its pretty bleeping scary and this is sam harr...   \n",
       "1  webography for dummies to make it in machine l...   \n",
       "2  technological unemployment and ubi reutersmura...   \n",
       "3  vantagepoint forex weekly outlook for march  t...   \n",
       "4  humanintheloop ai for emergency response more ...   \n",
       "\n",
       "                                               title              author  \\\n",
       "0                        It’s Pretty Bleeping Scary.      Peter Marshall   \n",
       "1  Webography for 4 dummies to make it in machine...  WELTARE Strategies   \n",
       "2                 Technological Unemployment and UBI  Michael K. Spencer   \n",
       "3  VantagePoint Forex Weekly Outlook for March 5t...     Vantagepoint ai   \n",
       "4  Human-in-the-Loop AI for Emergency Response & ...          TWiML & AI   \n",
       "\n",
       "  language                                                doc  \\\n",
       "0       en  (its, pretty, bleeping, scary, and, this, is, ...   \n",
       "1       en  (webography, for, dummies, to, make, it, in, m...   \n",
       "2       en  (technological, unemployment, and, ubi, reuter...   \n",
       "3       en  (vantagepoint, forex, weekly, outlook, for, ma...   \n",
       "4       en  (humanintheloop, ai, for, emergency, response,...   \n",
       "\n",
       "                                                 bow  \n",
       "0  [think, pretty, bleeping, scary, agi, absolute...  \n",
       "1  [create, file, touch, powershell, linux, langu...  \n",
       "2  [technological, human, amazon, world, robot, u...  \n",
       "3  [level, key, vantagepoint, market, pair, movem...  \n",
       "4  [figure, ai, twiml, machine, learning, rob, le...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = set()\n",
    "for x in range(len(df.text)):\n",
    "    common_words.update(df.bow[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3928f1ef739d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbow_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommon_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-6088bf198224>\u001b[0m in \u001b[0;36mbow_features\u001b[1;34m(sentences, common_words)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blaine\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blaine\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    654\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m             self.obj._data = self.obj._data.setitem(indexer=indexer,\n\u001b[1;32m--> 656\u001b[1;33m                                                     value=value)\n\u001b[0m\u001b[0;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blaine\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36msetitem\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'setitem'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blaine\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blaine\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36msetitem\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m         \u001b[1;31m# coerce and try to infer the dtypes of the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_coerce_and_cast_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    924\u001b[0m         \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blaine\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_try_coerce_and_cast_result\u001b[1;34m(self, result, dtype)\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_try_coerce_and_cast_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_coerce_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_cast_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blaine\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_try_cast_result\u001b[1;34m(self, result, dtype)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[1;31m# may need to change the dtype here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_downcast_to_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_try_coerce_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blaine\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mmaybe_downcast_to_dtype\u001b[1;34m(result, dtype)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'infer'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             inferred_type = lib.infer_dtype(ensure_object(result.ravel()),\n\u001b[0m\u001b[0;32m     79\u001b[0m                                             skipna=False)\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minferred_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "word_counts = pd.DataFrame()\n",
    "a = pd.from_pickle('C:\\\\duh\\Thinkful\\Thinkful\\Exercises\\a.pkl')\n",
    "b = pd.from_pickle('C:\\\\duh\\Thinkful\\Thinkful\\Exercises\\b.pkl')\n",
    "c = pd.from_pickle('C:\\\\duh\\Thinkful\\Thinkful\\Exercises\\c.pkl')\n",
    "d = pd.from_pickle('C:\\\\duh\\Thinkful\\Thinkful\\Exercises\\d.pkl')\n",
    "\n",
    "word_counts = word_counts.append([a, b, c, d], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_norm = normalize(X)\n",
    "\n",
    "#pca = PCA(.95)\n",
    "#X_pca = pca.fit_transform(X_norm)\n",
    "\n",
    "svd= TruncatedSVD(10)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_lsa = lsa.fit_transform(X)\n",
    "\n",
    "# Calculate predicted values.\n",
    "y_pred = KMeans(random_state=0).fit_predict(X_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(X_lsa[:, 0], X_lsa[:, 1], c=word_counts.text_source.drop_duplicates())\n",
    "plt.scatter(X_lsa[:, 2], X_lsa[:, 3], c=y_pred)\n",
    "plt.scatter(X_lsa[:, 4], X_lsa[:, 5], c=y_pred)\n",
    "plt.scatter(X_lsa[:, 6], X_lsa[:, 7], c=y_pred)\n",
    "plt.scatter(X_lsa[:, 8], X_lsa[:, 9], c=y_pred)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "        \n",
    "print('Training score: ', lr.score(X_train, y_train))\n",
    "print('Test score: ', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear')\n",
    "train = svm.fit(X_train, y_train)\n",
    "\n",
    "print('Training score: ', svm.score(X_train, y_train))\n",
    "print('Test score: ', svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
